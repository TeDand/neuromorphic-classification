{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "M6wlUTHDPNVt",
        "TdIup1SvWVrW",
        "Hg98ZPkDEl4H",
        "s_pe_8qLIwYQ",
        "lpsbffNMHJJs",
        "Zw3Lm6kXVH-u",
        "QfcDD37zVJrz",
        "z3CMHNrh0_3Q",
        "zug5kp69scug",
        "Z78BF2jGfv8P",
        "4A13558LTO1K",
        "qplmRjxsVFvr",
        "6EzWuicvugO3",
        "Jgd99HfPuo49",
        "9rY4HiYSf6SQ",
        "wHE0rf_HFo7D",
        "asr_LN6hFsI8",
        "X-nuKnS1lGhU",
        "-diMDzuslKXt"
      ],
      "authorship_tag": "ABX9TyO4yZwPJOwZqLV8bBQgBQ7q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TeDand/neuromorphic-classification/blob/main/video_reconstructions_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6wlUTHDPNVt"
      },
      "source": [
        "# Notebook Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdIup1SvWVrW"
      },
      "source": [
        "## Hardware Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHg3rTMGwx0q",
        "outputId": "45aa5278-0750-48d3-e2fe-6e6b320e366f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun 25 14:33:12 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    31W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n",
            "/device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')\n",
        "\n",
        "gpu = tf.test.gpu_device_name()\n",
        "print(gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_B2PrEYWYc4"
      },
      "source": [
        "## Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neM6UJMUsbF4",
        "outputId": "d857e92b-cf94-47f7-a933-3d9a4c6d7e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E2VID"
      ],
      "metadata": {
        "id": "Hg98ZPkDEl4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone Repository"
      ],
      "metadata": {
        "id": "s_pe_8qLIwYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/uzh-rpg/rpg_e2vid.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQq1vOgqI1_S",
        "outputId": "a4c9e7c4-2226-4d07-c3af-778c63fd2086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rpg_e2vid'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 74 (delta 26), reused 21 (delta 21), pack-reused 34\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run the video reconstruction model you need to run the following commands:\n",
        "\n",
        "```bash\n",
        "!cd rpg_e2vid/ && rm -rf outputs && mkdir outputs\n",
        "!cd rpg_e2vid/ && python run_reconstruction.py \\\n",
        "  -c pretrained/E2VID_lightweight.pth.tar \\\n",
        "  -i data/NMNIST/Train/0/08356.zip \\\n",
        "  --auto_hdr \\\n",
        "  --output_folder outputs/\n",
        "```"
      ],
      "metadata": {
        "id": "tNPgBuR9Ixl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Pre-Trained Weights and Data"
      ],
      "metadata": {
        "id": "lpsbffNMHJJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weights"
      ],
      "metadata": {
        "id": "Zw3Lm6kXVH-u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYqw2DG5EK9U",
        "outputId": "9e519c8a-02eb-4a30-930b-f9782f6770c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-12 21:47:30--  http://rpg.ifi.uzh.ch/data/E2VID/models/E2VID_lightweight.pth.tar\n",
            "Resolving rpg.ifi.uzh.ch (rpg.ifi.uzh.ch)... 130.60.75.162\n",
            "Connecting to rpg.ifi.uzh.ch (rpg.ifi.uzh.ch)|130.60.75.162|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://rpg.ifi.uzh.ch/data/E2VID/models/E2VID_lightweight.pth.tar [following]\n",
            "--2022-06-12 21:47:31--  https://rpg.ifi.uzh.ch/data/E2VID/models/E2VID_lightweight.pth.tar\n",
            "Connecting to rpg.ifi.uzh.ch (rpg.ifi.uzh.ch)|130.60.75.162|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://download.ifi.uzh.ch/rpg/web/data/E2VID/models/E2VID_lightweight.pth.tar [following]\n",
            "--2022-06-12 21:47:32--  https://download.ifi.uzh.ch/rpg/web/data/E2VID/models/E2VID_lightweight.pth.tar\n",
            "Resolving download.ifi.uzh.ch (download.ifi.uzh.ch)... 130.60.61.200\n",
            "Connecting to download.ifi.uzh.ch (download.ifi.uzh.ch)|130.60.61.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42878232 (41M) [application/x-tar]\n",
            "Saving to: ‘pretrained/E2VID_lightweight.pth.tar’\n",
            "\n",
            "pretrained/E2VID_li 100%[===================>]  40.89M  11.8MB/s    in 4.9s    \n",
            "\n",
            "2022-06-12 21:47:39 (8.26 MB/s) - ‘pretrained/E2VID_lightweight.pth.tar’ saved [42878232/42878232]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cd rpg_e2vid/ && wget \"http://rpg.ifi.uzh.ch/data/E2VID/models/E2VID_lightweight.pth.tar\" -O pretrained/E2VID_lightweight.pth.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Data"
      ],
      "metadata": {
        "id": "QfcDD37zVJrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd rpg_e2vid/ && wget \"http://rpg.ifi.uzh.ch/data/E2VID/datasets/ECD_IJRR17/dynamic_6dof.zip\" -O data/dynamic_6dof.zip"
      ],
      "metadata": {
        "id": "BiipDwqoVLeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DAVIS SLAM Dataset"
      ],
      "metadata": {
        "id": "z3CMHNrh0_3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://rpg.ifi.uzh.ch/datasets/davis/outdoors_running.zip -O /content/davis_data.zip\n",
        "!unzip -q /content/davis_data.zip -d /content/davis_data\n",
        "!rm -rf /content/davis_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PIwAFPg7z4E",
        "outputId": "5380d367-9c10-4732-88bf-cbb7af400595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-12 22:01:41--  https://rpg.ifi.uzh.ch/datasets/davis/outdoors_running.zip\n",
            "Resolving rpg.ifi.uzh.ch (rpg.ifi.uzh.ch)... 130.60.75.162\n",
            "Connecting to rpg.ifi.uzh.ch (rpg.ifi.uzh.ch)|130.60.75.162|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://download.ifi.uzh.ch/rpg/web/datasets/davis/outdoors_running.zip [following]\n",
            "--2022-06-12 22:01:43--  https://download.ifi.uzh.ch/rpg/web/datasets/davis/outdoors_running.zip\n",
            "Resolving download.ifi.uzh.ch (download.ifi.uzh.ch)... 130.60.61.200\n",
            "Connecting to download.ifi.uzh.ch (download.ifi.uzh.ch)|130.60.61.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 587238947 (560M) [application/zip]\n",
            "Saving to: ‘/content/davis_data.zip’\n",
            "\n",
            "/content/davis_data 100%[===================>] 560.03M  11.7MB/s    in 52s     \n",
            "\n",
            "2022-06-12 22:02:36 (10.9 MB/s) - ‘/content/davis_data.zip’ saved [587238947/587238947]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WtUIyBxl744H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/rpg_e2vid/data/DAVIS\n",
        "!wget https://rpg.ifi.uzh.ch/datasets/davis/outdoors_running.zip -O /content/rpg_e2vid/data/DAVIS/davis_data.zip\n",
        "!unzip -q /content/rpg_e2vid/data/DAVIS/davis_data.zip -d /content/rpg_e2vid/data/DAVIS/davis_data\n",
        "!rm -rf /content/rpg_e2vid/data/DAVIS/davis_data.zip\n",
        "!cd /content/rpg_e2vid/data/DAVIS/davis_data && rm -rf images\n",
        "!sed -i '1s/^/240 180\\n /' /content/rpg_e2vid/data/DAVIS/davis_data/events.txt\n",
        "!cd /content/rpg_e2vid/data/DAVIS/ && zip -r davis_data.zip davis_data/events.txt\n",
        "!rm -rf /content/rpg_e2vid/data/DAVIS/davis_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-vadByzjTku",
        "outputId": "34a2d1bb-03d9-47a1-ce57-b1f94d2e526b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/rpg_e2vid/data/DAVIS’: File exists\n",
            "--2022-06-12 21:48:49--  https://rpg.ifi.uzh.ch/datasets/davis/outdoors_running.zip\n",
            "Resolving rpg.ifi.uzh.ch (rpg.ifi.uzh.ch)... 130.60.75.162\n",
            "Connecting to rpg.ifi.uzh.ch (rpg.ifi.uzh.ch)|130.60.75.162|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://download.ifi.uzh.ch/rpg/web/datasets/davis/outdoors_running.zip [following]\n",
            "--2022-06-12 21:48:51--  https://download.ifi.uzh.ch/rpg/web/datasets/davis/outdoors_running.zip\n",
            "Resolving download.ifi.uzh.ch (download.ifi.uzh.ch)... 130.60.61.200\n",
            "Connecting to download.ifi.uzh.ch (download.ifi.uzh.ch)|130.60.61.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 587238947 (560M) [application/zip]\n",
            "Saving to: ‘/content/rpg_e2vid/data/DAVIS/davis_data.zip’\n",
            "\n",
            "/content/rpg_e2vid/ 100%[===================>] 560.03M  12.1MB/s    in 50s     \n",
            "\n",
            "2022-06-12 21:49:42 (11.2 MB/s) - ‘/content/rpg_e2vid/data/DAVIS/davis_data.zip’ saved [587238947/587238947]\n",
            "\n",
            "  adding: davis_data/events.txt (deflated 75%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/reconstructions\n",
        "!mkdir /content/reconstructions/\n",
        "!mkdir /content/reconstructions/DAVIS\n",
        "!python /content/rpg_e2vid/run_reconstruction.py \\\n",
        "  -c /content/rpg_e2vid/pretrained/E2VID_lightweight.pth.tar \\\n",
        "  -i /content/rpg_e2vid/data/DAVIS/davis_data.zip \\\n",
        "  --auto_hdr \\\n",
        "  --output_folder /content/reconstructions/DAVIS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6-urM0h4AI6",
        "outputId": "9422fcf9-d8b8-448d-816c-c66117d7f292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/rpg_e2vid/run_reconstruction.py:43: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype={'width': np.int, 'height': np.int},\n",
            "Sensor size: 240 x 180\n",
            "Loading model /content/rpg_e2vid/pretrained/E2VID_lightweight.pth.tar...\n",
            "Using TransposedConvLayer (fast, with checkerboard artefacts)\n",
            "Device: cuda:0\n",
            "== Image reconstruction == \n",
            "Image size: 180x240\n",
            "== Event preprocessing ==\n",
            "Will normalize event tensors.\n",
            "== Image Writer ==\n",
            "Will write images to: /content/reconstructions/DAVIS/reconstruction\n",
            "Will use 15119 events per tensor (automatically estimated with num_events_per_pixel=0.35).\n",
            "Will use fixed size event windows with 15119 events\n",
            "Output frame rate: variable\n",
            "== Timing statistics ==\n",
            "Events -> Device (voxel grid): 0.21 ms\n",
            "Voxel grid voting: 1.04 ms\n",
            "Reconstruction: 9.64 ms\n",
            "NumPy (CPU) -> Tensor (GPU): 0.02 ms\n",
            "Normalization: 0.28 ms\n",
            "Inference: 8.40 ms\n",
            "Unsharp mask: 0.14 ms\n",
            "Compute Imin/Imax (auto HDR): 0.29 ms\n",
            "Intensity rescaling: 0.13 ms\n",
            "Tensor (GPU) -> NumPy (CPU): 0.07 ms\n",
            "Processing entire dataset: 139.92 s\n",
            "Reading event window from file: 9.45 ms\n",
            "Building event tensor: 1.40 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMNIST"
      ],
      "metadata": {
        "id": "NcGHZkvsJQz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "zug5kp69scug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "!mkdir /content/NMNIST\n",
        "!wget -O \"NMNIST_training.zip\" \"https://data.mendeley.com/public-files/datasets/468j46mzdv/files/39c25547-014b-4137-a934-9d29fa53c7a0/file_downloaded\"\n",
        "!unzip -q NMNIST_training.zip -d /content/NMNIST\n",
        "!rm /content/NMNIST_training.zip\n",
        "!wget -O \"NMNIST_testing.zip\" \"https://data.mendeley.com/public-files/datasets/468j46mzdv/files/05a4d654-7e03-4c15-bdfa-9bb2bcbea494/file_downloaded\"\n",
        "!unzip -q NMNIST_testing.zip -d /content/NMNIST\n",
        "!rm /content/NMNIST_testing.zip\n",
        "!rm -rf /content/rpg_e2vid/data/NMNIST\n",
        "\n",
        "def read_events(input_file, output_file):\n",
        "  infile = open(input_file, \"rb\")\n",
        "  # reading 5 bytes (40 bits) at a time\n",
        "  event = int.from_bytes(infile.read(5), byteorder=\"little\", signed=False)\n",
        "  text = \"34 34\\n\"\n",
        "\n",
        "  while event:\n",
        "    # interpreting binary data\n",
        "    location_mask = 0b11111111\n",
        "    x_location = location_mask & event\n",
        "    y_location = location_mask & (event>>8)\n",
        "    polarity = 0b1 & (event>>16)\n",
        "    timestamp_mask = 0b11111111111111111111111\n",
        "    timestamp = timestamp_mask & (event>>17)\n",
        "    # appending to list of events\n",
        "    text = text + \"{0} {1} {2} {3}\\n\".format(timestamp, x_location, y_location, polarity)\n",
        "    # reading next event\n",
        "    event = int.from_bytes(infile.read(5), byteorder=\"little\", signed=False)\n",
        "\n",
        "  # Open a file with access mode 'a'\n",
        "  outfile = open(output_file, 'w')\n",
        "  # Append 'hello' at the end of file\n",
        "  outfile.write(text)\n",
        "  # Close the file\n",
        "  outfile.close()\n",
        "\n",
        "os.mkdir(\"/content/rpg_e2vid/data/NMNIST\")\n",
        "max_samples = 300\n",
        "\n",
        "def load_nmnist_samples(train):\n",
        "  print(\"Loading {0} samples\".format(\"training\" if train else \"testing\"))\n",
        "  folder = \"Train\" if train else \"Test\"\n",
        "  os.mkdir(\"/content/rpg_e2vid/data/NMNIST/{0}\".format(folder))\n",
        "  for act_class in range(10):\n",
        "    print(' class {0}'.format(act_class))\n",
        "    directory = \"/content/NMNIST/{0}/{1}/\".format(folder, act_class)\n",
        "    os.mkdir(\"/content/rpg_e2vid/data/NMNIST/{0}/{1}\".format(folder, act_class))\n",
        "    count = 0\n",
        "    for sample in os.listdir(directory):\n",
        "        zip_directory = \"/content/rpg_e2vid/data/NMNIST/{0}/{1}/{2}\".format(folder, act_class, sample[:-4])\n",
        "        input_directory = os.path.join(directory, sample)\n",
        "        output_directory = \"{0}/events.txt\".format(zip_directory)\n",
        "        if os.path.isfile(input_directory) and count < (max_samples if train else max_samples /4):\n",
        "            if(count % 60 != 0 or count == 0):\n",
        "              print(\".\", end=\"\")\n",
        "            else:\n",
        "              print(\".\")\n",
        "            os.mkdir(zip_directory)\n",
        "            events = read_events(input_directory, output_directory)\n",
        "            shutil.make_archive(zip_directory, 'zip', zip_directory)\n",
        "            shutil.rmtree(zip_directory, ignore_errors=False, onerror=None)\n",
        "        count = count + 1\n",
        "    print(\"\")\n",
        "\n",
        "load_nmnist_samples(train=True)\n",
        "load_nmnist_samples(train=False)\n",
        "\n",
        "!rm -rf /content/NMNIST"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oze93Y2QscZo",
        "outputId": "804ca977-c97d-431b-92fb-10f8393de584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-23 12:59:21--  https://data.mendeley.com/public-files/datasets/468j46mzdv/files/39c25547-014b-4137-a934-9d29fa53c7a0/file_downloaded\n",
            "Resolving data.mendeley.com (data.mendeley.com)... 162.159.133.86, 162.159.130.86\n",
            "Connecting to data.mendeley.com (data.mendeley.com)|162.159.133.86|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com/1afc103f-8799-464a-a214-81bb9b1f9337 [following]\n",
            "--2022-05-23 12:59:22--  https://md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com/1afc103f-8799-464a-a214-81bb9b1f9337\n",
            "Resolving md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com (md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com)... 52.218.88.80\n",
            "Connecting to md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com (md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com)|52.218.88.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1011893601 (965M) [application/x-zip-compressed]\n",
            "Saving to: ‘NMNIST_training.zip’\n",
            "\n",
            "NMNIST_training.zip 100%[===================>] 965.02M  20.8MB/s    in 48s     \n",
            "\n",
            "2022-05-23 13:00:11 (20.1 MB/s) - ‘NMNIST_training.zip’ saved [1011893601/1011893601]\n",
            "\n",
            "--2022-05-23 13:00:31--  https://data.mendeley.com/public-files/datasets/468j46mzdv/files/05a4d654-7e03-4c15-bdfa-9bb2bcbea494/file_downloaded\n",
            "Resolving data.mendeley.com (data.mendeley.com)... 162.159.133.86, 162.159.130.86\n",
            "Connecting to data.mendeley.com (data.mendeley.com)|162.159.133.86|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com/a99d0fee-a95b-4231-ad22-988fdb0a2411 [following]\n",
            "--2022-05-23 13:00:32--  https://md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com/a99d0fee-a95b-4231-ad22-988fdb0a2411\n",
            "Resolving md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com (md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com)... 52.218.80.11\n",
            "Connecting to md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com (md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com)|52.218.80.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169674850 (162M) [application/x-zip-compressed]\n",
            "Saving to: ‘NMNIST_testing.zip’\n",
            "\n",
            "NMNIST_testing.zip  100%[===================>] 161.81M  20.5MB/s    in 9.0s    \n",
            "\n",
            "2022-05-23 13:00:42 (18.0 MB/s) - ‘NMNIST_testing.zip’ saved [169674850/169674850]\n",
            "\n",
            "Loading training samples\n",
            " class 0\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 1\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 2\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 3\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 4\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 5\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 6\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 7\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 8\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 9\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            "Loading testing samples\n",
            " class 0\n",
            ".............................................................\n",
            "..............\n",
            " class 1\n",
            ".............................................................\n",
            "..............\n",
            " class 2\n",
            ".............................................................\n",
            "..............\n",
            " class 3\n",
            ".............................................................\n",
            "..............\n",
            " class 4\n",
            ".............................................................\n",
            "..............\n",
            " class 5\n",
            ".............................................................\n",
            "..............\n",
            " class 6\n",
            ".............................................................\n",
            "..............\n",
            " class 7\n",
            ".............................................................\n",
            "..............\n",
            " class 8\n",
            ".............................................................\n",
            "..............\n",
            " class 9\n",
            ".............................................................\n",
            "..............\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and Save Video Reconstructions"
      ],
      "metadata": {
        "id": "Z78BF2jGfv8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "!rm -rf /content/reconstructions\n",
        "os.mkdir(\"/content/reconstructions\")\n",
        "os.mkdir(\"/content/reconstructions/NMNIST\")\n",
        "\n",
        "def reconstruct_NMIST(train):\n",
        "  print(\"Reconstructing {0} samples\".format(\"training\" if train else \"testing\"))\n",
        "  folder = \"Train\" if train else \"Test\"\n",
        "  os.mkdir(\"/content/reconstructions/NMNIST/{0}\".format(folder))\n",
        "  for act_class in range(10):\n",
        "    print(' class {0}'.format(act_class))\n",
        "    recon_directory = \"/content/reconstructions/NMNIST/{0}/{1}/\".format(folder, act_class)\n",
        "    os.mkdir(recon_directory)\n",
        "    sample_directory = \"data/NMNIST/{0}/{1}/\".format(folder, act_class)\n",
        "    count = 0\n",
        "    for sample in os.listdir(\"/content/rpg_e2vid/{0}\".format(sample_directory)):\n",
        "      new_directory = \"{0}/{1}\".format(recon_directory, sample[:-4])\n",
        "      os.mkdir(new_directory)\n",
        "      if(count % 60 != 0 or count == 0):\n",
        "        print(\".\", end=\"\")\n",
        "      else:\n",
        "        print(\".\")\n",
        "      cmd = \"python /content/rpg_e2vid/run_reconstruction.py \\\n",
        "            -c /content/rpg_e2vid/pretrained/E2VID_lightweight.pth.tar \\\n",
        "            -i /content/rpg_e2vid/{0}/{1} \\\n",
        "            --auto_hdr \\\n",
        "            --output_folder {2}\".format(sample_directory, sample, new_directory)\n",
        "      # subprocess.call(cmd, shell=True)\n",
        "      process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
        "      output, error = process.communicate()\n",
        "      # print(output.decode(\"utf-8\") )\n",
        "      count = count + 1\n",
        "    print(\"\")\n",
        "\n",
        "reconstruct_NMIST(train=True)\n",
        "reconstruct_NMIST(train=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKBdytYZYCL6",
        "outputId": "c9eed4b3-46e5-4ab9-f432-f557cb6302b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructing training samples\n",
            " class 0\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 1\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 2\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 3\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 4\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 5\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 6\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 7\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 8\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 9\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            "Reconstructing testing samples\n",
            " class 0\n",
            ".............................................................\n",
            "..............\n",
            " class 1\n",
            ".............................................................\n",
            "..............\n",
            " class 2\n",
            ".............................................................\n",
            "..............\n",
            " class 3\n",
            ".............................................................\n",
            "..............\n",
            " class 4\n",
            ".............................................................\n",
            "..............\n",
            " class 5\n",
            ".............................................................\n",
            "..............\n",
            " class 6\n",
            ".............................................................\n",
            "..............\n",
            " class 7\n",
            ".............................................................\n",
            "..............\n",
            " class 8\n",
            ".............................................................\n",
            "..............\n",
            " class 9\n",
            ".............................................................\n",
            "..............\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Video Reconstructions"
      ],
      "metadata": {
        "id": "o_acYY9kR8ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q NMNIST_reconstructed.zip -d /content/reconstructions"
      ],
      "metadata": {
        "id": "UgQfYHZ3N8Nb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f19a4bbf-f583-4668-c7f9-6e58c102961a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/reconstructions/NMNIST/Test/6/08201/reconstruction/frame_0000004444.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "max_frame_count = 0\n",
        "\n",
        "print(\"Checking training reconstructions\")\n",
        "for act_class in range(10):\n",
        "    class_directory = \"/content/reconstructions/NMNIST/Train/{0}\".format(act_class)\n",
        "    for reconstruction in os.listdir(class_directory):\n",
        "      current_recon_dir = os.path.join(class_directory, reconstruction)\n",
        "      frame_count = 0\n",
        "      for frame in os.listdir(\"{0}/reconstruction\".format(current_recon_dir)):\n",
        "        f = os.path.join(\"{0}/reconstruction\".format(current_recon_dir), frame)\n",
        "        if frame.endswith('.png'):\n",
        "          frame_count += 1\n",
        "      if frame_count > max_frame_count:\n",
        "        max_frame_count = frame_count\n",
        "\n",
        "print(\"Checking testing reconstructions\")\n",
        "for act_class in range(10):\n",
        "    class_directory = \"/content/reconstructions/NMNIST/Test/{0}\".format(act_class)\n",
        "    for reconstruction in os.listdir(class_directory):\n",
        "      current_recon_dir = os.path.join(class_directory, reconstruction)\n",
        "      frame_count = 0\n",
        "      for frame in os.listdir(\"{0}/reconstruction\".format(current_recon_dir)):\n",
        "        f = os.path.join(\"{0}/reconstruction\".format(current_recon_dir), frame)\n",
        "        if frame.endswith('.png'):\n",
        "          frame_count += 1\n",
        "      if(frame_count > max_frame_count):\n",
        "        max_frame_count = frame_count\n",
        "\n",
        "print(\"The maximum video length in the dataset is {0} frames\".format(max_frame_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHX4T9PyQ8_w",
        "outputId": "958b105f-e5d8-4580-c456-2f50d250d6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking training reconstructions\n",
            "Checking testing reconstructions\n",
            "The maximum video length in the dataset is 20 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from itertools import islice, cycle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "print(\"Loading training reconstructions\")\n",
        "for act_class in range(10):\n",
        "    print(' class {0}'.format(act_class))\n",
        "    class_directory = \"/content/reconstructions/NMNIST/Train/{0}\".format(act_class)\n",
        "    count = 0\n",
        "    for reconstruction in os.listdir(class_directory):\n",
        "      current_recon_dir = os.path.join(class_directory, reconstruction)\n",
        "      if(count % 60 != 0 or count == 0):\n",
        "        print(\".\", end=\"\")\n",
        "      else:\n",
        "        print(\".\")\n",
        "      current_recon = []\n",
        "      for frame in os.listdir(\"{0}/reconstruction\".format(current_recon_dir)):\n",
        "        f = os.path.join(\"{0}/reconstruction\".format(current_recon_dir), frame)\n",
        "        if frame.endswith('.png'):\n",
        "          im = imageio.imread(f)\n",
        "          current_recon.append(im)\n",
        "      current_recon = list(islice(cycle(current_recon), max_frame_count))\n",
        "      x_train.append(current_recon)\n",
        "      y_train.append(np_utils.to_categorical(act_class, 10))\n",
        "      count = count + 1\n",
        "    print(\"\")\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "print(\"Loading testing reconstructions\")\n",
        "for act_class in range(10):\n",
        "    print(' class {0}'.format(act_class))\n",
        "    class_directory = \"/content/reconstructions/NMNIST/Test/{0}\".format(act_class)\n",
        "    count = 0\n",
        "    for reconstruction in os.listdir(class_directory):\n",
        "      current_recon_dir = os.path.join(class_directory, reconstruction)\n",
        "      if(count % 60 != 0 or count == 0):\n",
        "        print(\".\", end=\"\")\n",
        "      else:\n",
        "        print(\".\")\n",
        "      current_recon = []\n",
        "      for frame in os.listdir(\"{0}/reconstruction\".format(current_recon_dir)):\n",
        "        f = os.path.join(\"{0}/reconstruction\".format(current_recon_dir), frame)\n",
        "        if frame.endswith('.png'):\n",
        "          im = imageio.imread(f)\n",
        "          current_recon.append(im)\n",
        "      current_recon = list(islice(cycle(current_recon), max_frame_count))\n",
        "      x_test.append(current_recon)\n",
        "      y_test.append(np_utils.to_categorical(act_class, 10))\n",
        "      count = count + 1\n",
        "    print(\"\")\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], x_train.shape[3], 1)\n",
        "train_set = x_train.astype('float32')\n",
        "train_set -= np.mean(x_train)\n",
        "train_set /= np.max(x_train)\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3], 1)\n",
        "test_set = x_test.astype('float32')\n",
        "test_set -= np.mean(x_train)\n",
        "test_set /= np.max(x_train)\n",
        "\n",
        "x_train = train_set\n",
        "x_test = test_set\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "x_train, x_val, y_train, y_val=  train_test_split(x_train, y_train, test_size=0.2, random_state=4)"
      ],
      "metadata": {
        "id": "MoHoXkNxUQ6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e642f115-98e8-4532-9830-fb06f366ea37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training reconstructions\n",
            " class 0\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 1\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 2\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 3\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 4\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 5\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 6\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 7\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 8\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            " class 9\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...........................................................\n",
            "Loading testing reconstructions\n",
            " class 0\n",
            ".............................................................\n",
            "..............\n",
            " class 1\n",
            ".............................................................\n",
            "..............\n",
            " class 2\n",
            ".............................................................\n",
            "..............\n",
            " class 3\n",
            ".............................................................\n",
            "..............\n",
            " class 4\n",
            ".............................................................\n",
            "..............\n",
            " class 5\n",
            ".............................................................\n",
            "..............\n",
            " class 6\n",
            ".............................................................\n",
            "..............\n",
            " class 7\n",
            ".............................................................\n",
            "..............\n",
            " class 8\n",
            ".............................................................\n",
            "..............\n",
            " class 9\n",
            ".............................................................\n",
            "..............\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytxpiFqSPUPU",
        "outputId": "72e22e29-dc1e-46c7-e261-97dc5b124304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2400, 20, 34, 34, 1)\n",
            "(2400, 10)\n",
            "(750, 20, 34, 34, 1)\n",
            "(750, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Networks"
      ],
      "metadata": {
        "id": "KcGRszufJ0fO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3D Convolutional Network"
      ],
      "metadata": {
        "id": "JsPMWUEFTLQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\n",
        "import keras\n",
        "\n",
        "# Initialing the Training Parameters\n",
        "batch_size = 32\n",
        "nb_classes = 10\n",
        "nb_epoch = 120\n",
        "\n",
        "# Number of convolutional filters to use at each layer\n",
        "nb_filters = 32\n",
        "# Level of pooling to perform at each layer (POOL x POOL)\n",
        "nb_pool = 2\n",
        "# Level of convolution to perform at each layer (CONV x CONV)\n",
        "nb_conv = 5\n",
        "\n",
        "# Defining the 3D Convolution Neural Network model\n",
        "model = Sequential()\n",
        "model.add(Convolution3D(nb_filters,kernel_size=nb_conv,input_shape=x_train.shape[1:], activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution3D(nb_filters,kernel_size=nb_conv,input_shape=x_train.shape[1:], activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D(pool_size=nb_pool,padding='same'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution3D(nb_filters*2,kernel_size=nb_conv,activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D(pool_size=nb_pool,padding='same'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution3D(nb_filters*4,kernel_size=nb_conv,activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution3D(nb_filters*4,kernel_size=nb_conv,activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D(pool_size=nb_pool,padding='same'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,kernel_initializer = 'he_normal',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(nb_classes,kernel_initializer = 'he_normal'))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt=Adam(lr=0.0001)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "logdir = \"logs/scalars/conv3d_nmnist\"\n",
        "\n",
        "# Training  the model along with creating callbacks to tensorboard for graphical visualization of training process\n",
        "tbcallback = keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=True, write_images=True)\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n",
        "hist = model.fit(x_train, y_train, validation_data=(x_val,y_val),\n",
        "          batch_size=batch_size,epochs = nb_epoch,shuffle=True,verbose=1,callbacks=[tbcallback, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwrdn5-SE0Xd",
        "outputId": "7146239e-df68-40ab-8b58-05bf5feb5e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "75/75 [==============================] - 15s 182ms/step - loss: 2.6456 - accuracy: 0.2325 - val_loss: 2.8469 - val_accuracy: 0.1083\n",
            "Epoch 2/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 1.7738 - accuracy: 0.4496 - val_loss: 3.8887 - val_accuracy: 0.1083\n",
            "Epoch 3/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 1.3908 - accuracy: 0.5708 - val_loss: 6.9408 - val_accuracy: 0.1083\n",
            "Epoch 4/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 1.1817 - accuracy: 0.6179 - val_loss: 6.3587 - val_accuracy: 0.1083\n",
            "Epoch 5/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 1.0178 - accuracy: 0.6812 - val_loss: 6.4972 - val_accuracy: 0.1617\n",
            "Epoch 6/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.9197 - accuracy: 0.6917 - val_loss: 3.3641 - val_accuracy: 0.3033\n",
            "Epoch 7/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.7900 - accuracy: 0.7400 - val_loss: 1.7814 - val_accuracy: 0.4883\n",
            "Epoch 8/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.7519 - accuracy: 0.7500 - val_loss: 1.1124 - val_accuracy: 0.6617\n",
            "Epoch 9/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.6734 - accuracy: 0.7833 - val_loss: 0.8287 - val_accuracy: 0.7400\n",
            "Epoch 10/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.5748 - accuracy: 0.8037 - val_loss: 0.7508 - val_accuracy: 0.7550\n",
            "Epoch 11/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.5257 - accuracy: 0.8250 - val_loss: 0.7520 - val_accuracy: 0.7583\n",
            "Epoch 12/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.4643 - accuracy: 0.8500 - val_loss: 0.6579 - val_accuracy: 0.7900\n",
            "Epoch 13/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.4387 - accuracy: 0.8529 - val_loss: 0.8098 - val_accuracy: 0.7883\n",
            "Epoch 14/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.4056 - accuracy: 0.8692 - val_loss: 0.6000 - val_accuracy: 0.8250\n",
            "Epoch 15/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.3880 - accuracy: 0.8687 - val_loss: 0.5500 - val_accuracy: 0.8283\n",
            "Epoch 16/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.3426 - accuracy: 0.8933 - val_loss: 0.5937 - val_accuracy: 0.8117\n",
            "Epoch 17/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.3246 - accuracy: 0.8896 - val_loss: 0.5895 - val_accuracy: 0.8017\n",
            "Epoch 18/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.2758 - accuracy: 0.9133 - val_loss: 0.6985 - val_accuracy: 0.7800\n",
            "Epoch 19/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.2818 - accuracy: 0.9112 - val_loss: 0.5340 - val_accuracy: 0.8317\n",
            "Epoch 20/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.2659 - accuracy: 0.9121 - val_loss: 0.5597 - val_accuracy: 0.8300\n",
            "Epoch 21/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.2171 - accuracy: 0.9275 - val_loss: 0.5915 - val_accuracy: 0.8100\n",
            "Epoch 22/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.2060 - accuracy: 0.9396 - val_loss: 0.5492 - val_accuracy: 0.8450\n",
            "Epoch 23/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.1837 - accuracy: 0.9488 - val_loss: 0.6191 - val_accuracy: 0.8100\n",
            "Epoch 24/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.1712 - accuracy: 0.9513 - val_loss: 0.5738 - val_accuracy: 0.8367\n",
            "Epoch 25/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.1413 - accuracy: 0.9613 - val_loss: 0.5080 - val_accuracy: 0.8450\n",
            "Epoch 26/120\n",
            "75/75 [==============================] - 13s 178ms/step - loss: 0.1326 - accuracy: 0.9663 - val_loss: 0.5213 - val_accuracy: 0.8383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\n",
        "import keras\n",
        "\n",
        "# Initialing the Training Parameters\n",
        "batch_size = 32\n",
        "nb_classes = 10\n",
        "nb_epoch = 120\n",
        "\n",
        "# Number of convolutional filters to use at each layer\n",
        "nb_filters = 32\n",
        "# Level of pooling to perform at each layer (POOL x POOL)\n",
        "nb_pool = 2\n",
        "# Level of convolution to perform at each layer (CONV x CONV)\n",
        "nb_conv = 5\n",
        "\n",
        "# Defining the 3D Convolution Neural Network model\n",
        "model = Sequential()\n",
        "model.add(Convolution3D(nb_filters,kernel_size=nb_conv,input_shape=x_train.shape[1:], activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution3D(nb_filters,kernel_size=nb_conv,input_shape=x_train.shape[1:], activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D(pool_size=nb_pool,padding='same'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution3D(nb_filters*2,kernel_size=nb_conv,activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D(pool_size=nb_pool,padding='same'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution3D(nb_filters*4,kernel_size=nb_conv,activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution3D(nb_filters*4,kernel_size=nb_conv,activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D(pool_size=nb_pool,padding='same'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,kernel_initializer = 'he_normal',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(nb_classes,kernel_initializer = 'he_normal'))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt=Adam(lr=0.0001)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "logdir = \"logs/scalars/conv3d_nmnist\"\n",
        "\n",
        "# Training  the model along with creating callbacks to tensorboard for graphical visualization of training process\n",
        "tbcallback = keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=True, write_images=True)\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n",
        "hist = model.fit(x_train, y_train, validation_data=(x_val,y_val),\n",
        "          batch_size=batch_size,epochs = nb_epoch,shuffle=True,verbose=1,callbacks=[tbcallback, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNL3ESObTPeB",
        "outputId": "c24bbcd3-6f3f-404e-85b9-49ff9f87c483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 20, 34, 34, 32)    4032      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 20, 34, 34, 32)   128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 20, 34, 34, 32)    128032    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 20, 34, 34, 32)   128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 10, 17, 17, 32)   0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10, 17, 17, 32)    0         \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 10, 17, 17, 64)    256064    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 17, 17, 64)   256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 5, 9, 9, 64)      0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5, 9, 9, 64)       0         \n",
            "                                                                 \n",
            " conv3d_3 (Conv3D)           (None, 5, 9, 9, 128)      1024128   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 5, 9, 9, 128)     512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3d_4 (Conv3D)           (None, 5, 9, 9, 128)      2048128   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 5, 9, 9, 128)     512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPooling  (None, 3, 5, 5, 128)     0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3, 5, 5, 128)      0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1228928   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,692,650\n",
            "Trainable params: 4,691,626\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "75/75 [==============================] - 28s 188ms/step - loss: 2.6691 - accuracy: 0.2217 - val_loss: 2.7249 - val_accuracy: 0.1083\n",
            "Epoch 2/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 1.7808 - accuracy: 0.4250 - val_loss: 3.8360 - val_accuracy: 0.1083\n",
            "Epoch 3/120\n",
            "75/75 [==============================] - 14s 180ms/step - loss: 1.4365 - accuracy: 0.5400 - val_loss: 5.4225 - val_accuracy: 0.1050\n",
            "Epoch 4/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 1.2078 - accuracy: 0.6137 - val_loss: 6.0552 - val_accuracy: 0.1117\n",
            "Epoch 5/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 1.0115 - accuracy: 0.6675 - val_loss: 5.2817 - val_accuracy: 0.1750\n",
            "Epoch 6/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.8938 - accuracy: 0.7075 - val_loss: 4.2255 - val_accuracy: 0.2100\n",
            "Epoch 7/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.7526 - accuracy: 0.7563 - val_loss: 2.9013 - val_accuracy: 0.3117\n",
            "Epoch 8/120\n",
            "75/75 [==============================] - 13s 180ms/step - loss: 0.6781 - accuracy: 0.7800 - val_loss: 1.6758 - val_accuracy: 0.5467\n",
            "Epoch 9/120\n",
            "75/75 [==============================] - 13s 180ms/step - loss: 0.6543 - accuracy: 0.7854 - val_loss: 1.0512 - val_accuracy: 0.6650\n",
            "Epoch 10/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.5844 - accuracy: 0.8092 - val_loss: 0.6905 - val_accuracy: 0.7767\n",
            "Epoch 11/120\n",
            "75/75 [==============================] - 13s 180ms/step - loss: 0.5349 - accuracy: 0.8200 - val_loss: 0.6772 - val_accuracy: 0.7817\n",
            "Epoch 12/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.4884 - accuracy: 0.8271 - val_loss: 0.5871 - val_accuracy: 0.7983\n",
            "Epoch 13/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.4583 - accuracy: 0.8433 - val_loss: 0.7635 - val_accuracy: 0.7367\n",
            "Epoch 14/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.4168 - accuracy: 0.8592 - val_loss: 0.5379 - val_accuracy: 0.8200\n",
            "Epoch 15/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.3867 - accuracy: 0.8671 - val_loss: 0.5733 - val_accuracy: 0.8050\n",
            "Epoch 16/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.3460 - accuracy: 0.8829 - val_loss: 0.5329 - val_accuracy: 0.8133\n",
            "Epoch 17/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.3021 - accuracy: 0.9046 - val_loss: 0.5575 - val_accuracy: 0.8183\n",
            "Epoch 18/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.2919 - accuracy: 0.9083 - val_loss: 0.5202 - val_accuracy: 0.8317\n",
            "Epoch 19/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.2523 - accuracy: 0.9183 - val_loss: 0.5104 - val_accuracy: 0.8250\n",
            "Epoch 20/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.2438 - accuracy: 0.9258 - val_loss: 0.5386 - val_accuracy: 0.8283\n",
            "Epoch 21/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.2145 - accuracy: 0.9371 - val_loss: 0.5286 - val_accuracy: 0.8250\n",
            "Epoch 22/120\n",
            "75/75 [==============================] - 13s 179ms/step - loss: 0.1949 - accuracy: 0.9429 - val_loss: 0.5868 - val_accuracy: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/MyDrive/models/conv3d_nmnist_recon.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "# del model  # deletes the existing model"
      ],
      "metadata": {
        "id": "QCA0XJChT-yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results"
      ],
      "metadata": {
        "id": "3_sbHoZ1TwRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/models/conv3d_nmnist_recon.h5')"
      ],
      "metadata": {
        "id": "QBe2tYgHT0hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "y_pred = model.predict(x_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaPdbJodTym0",
        "outputId": "32fd8735-291e-4531-cae3-3619e29aa24e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.47015225887298584\n",
            "Test accuracy: 0.8666666746139526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdw4j2kmUKnV",
        "outputId": "1a10f851-bf3f-4966-a436-d9b5ed6484e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95        75\n",
            "           1       0.95      0.96      0.95        75\n",
            "           2       0.85      0.93      0.89        75\n",
            "           3       0.84      0.71      0.77        75\n",
            "           4       0.93      0.84      0.88        75\n",
            "           5       0.71      0.87      0.78        75\n",
            "           6       0.87      0.91      0.89        75\n",
            "           7       0.91      0.85      0.88        75\n",
            "           8       0.86      0.73      0.79        75\n",
            "           9       0.85      0.91      0.88        75\n",
            "\n",
            "    accuracy                           0.87       750\n",
            "   macro avg       0.87      0.87      0.87       750\n",
            "weighted avg       0.87      0.87      0.87       750\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import seaborn as sns\n",
        "\n",
        "#Create confusion matrix and normalizes it over predicted (columns)\n",
        "result = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), normalize='pred')\n",
        "\n",
        "ax = sns.heatmap(result, annot=False, cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix for Reconstructed NMNIST Classification with Conv3D Network\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([i for i in range(10)])\n",
        "ax.yaxis.set_ticklabels([i for i in range(10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "4PNrUVYtUMO3",
        "outputId": "1a2c64ef-4190-45ef-fa22-40eafea2503d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0.5, '0'),\n",
              " Text(0, 1.5, '1'),\n",
              " Text(0, 2.5, '2'),\n",
              " Text(0, 3.5, '3'),\n",
              " Text(0, 4.5, '4'),\n",
              " Text(0, 5.5, '5'),\n",
              " Text(0, 6.5, '6'),\n",
              " Text(0, 7.5, '7'),\n",
              " Text(0, 8.5, '8'),\n",
              " Text(0, 9.5, '9')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFACAYAAACVw/T2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd7xcdZ3/8df73gRC77B02AWUiDRDEaQo6IIgWFgJNlQgooKIFdf9UXXXirKAi6FJkSBNjIgUka5AQhMSWkQgIUgJoQZMuZ/fH9/vhck4c++c5MycO8n7mcc8cue07/fMnDnv8/2eM2cUEZiZmVn36Km6AmZmZlaMw9vMzKzLOLzNzMy6jMPbzMysyzi8zczMuozD28zMrMtUGt6SlpL0W0kvSrp4IZbzcUnXlFm3Kkj6vaQDF3De70h6TtLfy66XLRxJj0navep6VE1SSNqoTcuebx8gaUdJj0h6RdIHF+azNUi5p0n6f2Uvt6zyJR0r6fxO1smKk3SDpIMLzRQRgz6AjwETgVeAp4DfA+9qZd5BlvtJ4A5g2MIuqx0PYFcggF/XDd8iD7+hxeUcC5zfxnquB7wGrF7iMgN4Nb/nTwInAr1VvycN6rlBrmtbtqG8DUxbyGU8BuzeZNwvcv23rRm2UfpovvH8hjzNFnXz/joP37VmOwvgozXTDMvDNqgp7zs14w8CHgReBp4GrgSWy5/xV/JjDjC75vlpTdZlTeDMvI94OS/3OGCZmm1qow5tF9cBR5S8zE8Dt3Si/mVtq0X3PYCALwH358//NOBi4O1trvuRwKPAS8B04Ce1n+m6/dGM/P7uP8gyHwOe6d/+8rCDaX2/Pd9npc3rfwNwcJF5Bm15S/oK8FPgv4E1SEHxM2DfweZtwfrAwxExt4RltcuzwDslrVIz7EDg4bIKULIwvSDrATMi4pkFKHvYAKO3iIhlgV2A/YHPLmD9KjXIOg4FzwPfGWSah4FP9T/J2+M7Sdtn/bKOk9Q7WKGSdiF9rg+IiOWATYFfAUTEnhGxbH7/fwn8oP95RBzaYFkrA38GlgLemZf3XmBF4N8Gq0sbrA9MqqDcbncScAQpwFcGNgEuB/Zqc7njga0jYnlgM1ID6Ut10/Tvj95CCtZTJB0zyHJ7SeszJC3Uvn+Qo4EVSEc6/zHANEuSwn16fvwUWLL2SBD4KukI6CngM3nccaSj+Tm5jIOoO0qkrlVFOvJ9lHRU/zfg4zXDb6mZbwdgAvBi/n+HuiOcE4Bb83KuAVZtsm799T8N+GIe1ktqiR5NzREcaaOfSjpyvBPYKQ/fo249762px3dzPV4jtbZuIB99Af8HXFqz/O+TjjZVV8fd8/x9efm/yMP3Ie28XsjL3bTuiPSbwF+Af9Cg1UpdKwm4CDi15vnewD15+X8CNq8Zty5wGSlYZgCn5OE9wH8Bj+ft4Vxghbr3+kDgCeA54Ns1y9yW1PvzEqmFeGIe/kSer79V+M68PdxKOnqfQQrGYxl421oZOJu0Dc8k7bCWqXttXwHWyutxFPDXvPyLgJVrlv3JvI4zgG8zeMv7RODvwC55WKOW99GkbbE3DzssbyPTmL/l/UvgXuDAPKxpyxv4GnB5C62CN+YZYJrvAPcBPQNM88Y2RQqDu/P7ORU4tma6EcD5+fV7gfQZXqPVfUB+X/rye/cKaR91AzUtG+AQ4IG8nMmk4KDmfe0f/qE8fFPgdWBeXuYLjV6bvNwppIOo8cBadet/KPBIXq9Tqfs816z/a+T9Ut6G5gLL5+cnAD+tLZ/m2+qxpO3z3LxOk4BRTd6fjfP6bdtofE0mnEv6bD9O+jz31L4HwI9In6G/AXvmcfsDE+uWdSQwvkEZqwB/AH7WbH+Uh+2X35NVmtT1sfx+Pg+smIfN1/IG3gpcm6d5iNxrBYxh/h6n3wKfAX5bM+8jwMU1z6cCW+a/B8uggfb9a5L2zV8f8DM3yAdyj7zRNO2SBI4HbgNWB1Yj7chPyON2zfMfDwwH3g/MAlaq2dnU7lDrn2+Q37RhpI3zJeAtNSv4tgYf3JXzhvPJPN8B+fkqNS/cX0lHlEvl599rsm67knaOOwC352HvB65usBF8grTRDSMdrPwdGNFovWrq8QTwtjzP8Lo3cGlSa+vTwE6kMFtnoHrWPN+E1MX03rzcb5B2KEvUbNT3kEJ2qRZ2tG8lHXgdmZ9vRQrf7UgHMwfmZS6Zn99LCs5lSDuid+X5Ppvr8a/AsqSAP6/uvT49vy9bkA4sNs3j/wx8Mv+9LLB9/TZSU/dPk7a7w/Nru1T9e1A/H/A7Uqtzpfya7dLotc3DjiBt8+vkdf45MC6PG0n6sO+cx52Y6zJQeH+H1Mro34YbhffBpAPN/p3hHaQDlfrwPp904PZoXo+Bwnsn0s7jOGBH8kF3szoOsq+4DThukGlqt6ldgbeTDoQ2Jx2QfTCP+xxpZ7k0aXt6B7A8Le4Darbx3etfw/z3f5AOwLchdRNvBKxfM67/AG1/0udozUZlNHg930P6nG6d3/uTgZvq1v8KUm/EeqQA3KPJa3UT8JH89zWkfdaeNeM+1KD8XWncbf46ab/VC/wPcFuTMg8FHh/kPTwX+A3p1MoGpH3UQTWvzxzSAUwv8HnSwbDye/kysHHNsiYAo2uefyy/v5Ffmy3qXrv68B5O+mzt2aSuj5EaN5fVvEZv7LdJ29NUUigPI+3XngNGNtruSfutF/K2sRbp4GVazbiZeVwrGdRw3w9smF/TMQO9DxGDd5uvAjwXA3drfxw4PiKeiYhnSTuCT9aMn5PHz4mIK0k7trcMUm4zfcBmkpaKiKciolG32F7AIxFxXkTMjYhxpHNvH6iZ5uyIeDgiXiMdlW45UKER8SdgZUlvIXVdnttgmvMjYkYu88ekD+9g6/mLiJiU55lTt7xZpNfxRNIO+fCImDbI8vrtD/wuIq7Ny/0RKcB2qJnmfyNian4NmrlL0qukFsoNpNMlkI5Kfx4Rt0fEvIg4hxS025NayGuRjhpfjYjXI+KWPN/HSS3mRyPiFeBbwOi6bu3jIuK1iLiXdBCwRR4+B9hI0qoR8UpE3DbIazA9Ik7Or+1A64ikNYE9gUMjYmbeVm8cYJZDSb0C0yLiH6Qd5H55PfYDroiIm/K4/0fabgfzc2A9SXsOMM25wKckvZXUkvhzo4kiYjxp5zfgBTARcTPwYVLY/A6YIenEVrrcG1iFdIDXkoi4ISLui4i+iPgLMI50egbSe70KaWc9LyLujIiX8rhW9gGDOZh0GmBCJFMi4vFcr4sjYnqu169IrattW1zux4GzIuKu/N5/i3TKbYOaab4XES9ExBPA9TTf99wI7JK3qc2B/83PR5AOOm4qsL63RMSVETEPOI83P1P1BnwP83YxGvhWRLwcEY8BP2b+/f3jEXF6Lusc0gHWGnl/9htSkCFpY1KjYHz/jBFxQaRu801IvZ1PD7RSed/2HCksB3I0cLik1eqG7w08FhFn5/3E3cClpAO4RuX19/hsSTo4vxqYnj+PuwA3R0QfrWVQo33/SNI2cUxEjB1knQYN7xnAqoOcM+w/Aun3eB72xjLqwn8WqeVUSES8SgqlQ4GnJP0uv2iD1ae/TmvXPK+9IrvV+pxH6qp8N+lCoflI+pqkB/KV8y+QupdWHWSZUwcaGRG3k1pQIh1ktGq+1yBvUFOZ/zUYsOxsa9Jrsz+plb1MHr4+8FVJL/Q/SK34tfL/jzc54Gu0rQwjXUvRr9l7cxDpQ/2gpAmS9h6k7q2sX791gecjYmaL068P/Lpm3R8gdTeuQVrHN8rO2+2MwRaYd/Yn5Eczl5Fad4eRtseB/Bepu3XEIOX+PiI+QNoB7ktqPRW76jWZQdpRt0TSdpKul/SspBdJn+v+z8t5pB3jhZKmS/qBpOEF9gGDWZfUkm1Ur09Juqfmvd2MwT/H/eo/d/0XVy3IvudGUkt6a9LpiGtJAbE9MCUiBt2mBihzRJN9+mDv4aqkVmL9Z7jh+uXAhjfX8QJyeJNa2ZfXTEPNfI+Quvd/Vj+ulqThpN7e5weaLiLuJ/V4HFU3an1gu7r92MeBfxlgcf3vy8757xtI78su+Tm0lkGN9k8fJ/UIXTLQ+vQbLLz/TGpRfXCAaaaTXoR+6+VhC+JVUvdKv/lexIi4OiLeS9rAHiR1sQ5Wn/46PbmAdep3HvAF4Mr6DU7STqSu6Y+STgmsSDrXof6qN1lms+H9y/0iqQU/PS+/VfO9BpJE2mHVvgYDlv3GRMlFpG3h6Dx4KvDdiFix5rF0PsKcSmpBNto5NNpW5jLIEXauxyMRcQDp9Mz3gUskLTPAetQPH2jbmkrqWVmxheX0T79n3fqPiIgnSS2XdfsnlLQ0qUXTirNJXaofbjQyb3e/J3VHDhjeEXEt6RTFF1opOLc0rwP+SAqsov4AfKjAxTcXkFpd60bECqSWlnJd5kTEcRExktRbtDf5Yr0W9wGDmUqDi+gkrZ+Xdxipi3NF0lXXg32O+9V/7pYhvfcLsu/5E6nn7kPAjRExmfR5eT9vhkS9lj7TA7gOWEfSqCbjnyP1itR/hltdv2uB1SRtSQrxCwaYdhiDX+i4L2n/cUcLZR9D6s6vD9Ab6z7Hy0bE5/P4Rq9nf3jvlP++kX8O71YyqNGyjyW9xhe00vs14ActIl4k7bBPzd+VXFrScEl7SvpBnmwc8F+SVpO0ap5+Qb9XeA+ws6T1JK1A6nYCQNIakvbNH4h/kLrfG3VHXglsIuljkoZJ2p/UHXHFAtYJgIj4G+kN+naD0cuRNqJngWGSjiado+v3NLBBkasKJW1COhf6CVK31DfyRt+Ki4C9JO2Wj06/SnrN/tRq+Q18DzhE0r+QdnCH5taTJC0jaS9Jy5E+SE8B38vDR0jaMS9jHHCkpA0lLUu60vlXTVrp85H0CUmr5V6EF/LgPtJr3kc65zSQpttWRPR//fFnklbK2/jOefTTwCp5nn6nAd/NO3vytt//7YtLgL0lvUvSEqTrPVp63/PrcAzpYsJm/pN0Pv6xFhb5bQY46Mufp9F5nSVpW9I2PtgpiUZOJG3z59S8LmvnbvjNG0y/HKm34/Vc7sdq6vVuSW/PO7CXSIHRV2AfMJgzgK9Jekde741ynfsPBp/N9fgM8x/IPE0KtyWaLHcc8BlJW0pakrR9397iezWffKB2J/BF3gyFP5F6HZqFd6NttUiZj5Bau+Mk7Sppifz5HS3pqNwVfhFp218uv2ZfocX9fe4evhj4Iamn59r+cZIOlrR6/nsk6fN5XaPlSFpZ0sdJF/x9v5VeiIiYQrqmpfYK9itIWfHJ/JkfLmkbSZvm8U/zz/uVG0m9r0tFOo15M+nasFVIF2DCgmfQHFKX/TLAuYPlxaA7lUjnb79C6oZ7lnS0chjpalxIATORdHXcfcBdDP61l2ZlXUt6gf9C2nBrV7Yn12M6qZtkF1ILpH4ZM0hH6l8ldQN9A9g7Ip5bkDrVLfuWiGjUq3A1cBXpQoPHSReI1HaL9N+AZoakuwYrJ7dazydtmPfmD9V/AuflncJg9XyIFPonk47kPgB8ICJmDzbvAMu8j3Se7esRMZF0FHsK6UKMKaTuVvIH/AOki4CeIF1QtX9ezFmkFuNNpCtRXyddVNaKPYBJkl4hXdk/OtK58VnkKzdz19f2Teo/0LYF6QBpDqk19wzw5Tzfg6Sd8qN5+Wvl8scD10h6mRR22+XpJ5F2uBeQDmJm5tegVeMY4LxjPh97S7PxddPeysCtkpmk9/ERUkieD/wwIn7ZenXfKOt5Uit5DnB7fl2uI/VATWkwyxeA4/N0RzP/aaF/IR0EvUQ6JXEjabtpaR/QQl0vJm0zF5DOYV5O+rbAZNI53D+TdtxvJ10R3O+PpO7cv0v6p/1JRPyBdI3DpaT38N9I54gX1I2kbuo7ap4vR5Pz3U221aK+RPpcn0o6SP4rqfX/2zz+cFIv1qOkK8svIH2uW3UB6SKyi+sO2ncE7lO6xubK/PjPunnvzZ//KaRTO0dGxNG07njePPVHRLwMvI/0Hk0ndfl/n9TbCemeBSPza3l5nudh0kHjzfn5S6TX4ta871uoDMr76A+TTsGdNVCAK2Jhe1rMzMysk3xvczMzsy7j8DYzM+syDm8zM7Mu4/A2MzPrMg5vMzOzLuPwNjMz6zIObzMzsy7j8DYzM+syDm8zM7Mu4/A2MzPrMg5vMzOzLuPwNjMz6zIObzMzsy7j8DYzM+syDm8zM7Mu4/A2MzPrMg5vMzOzLuPwNjMz6zIObzMzsy7j8DYzM+syDm8zM7Mu4/A2MzPrMg5vMzOzLuPwNjMz6zIObzMzsy7j8DYzM+syDm8zM7Mu4/A2MzPrMg5vMzOzLuPwNjMz6zIObzMzsy7j8DYzM+syDm8zM7Mu4/A2MzPrMg5vMzOzLjOs6gpYOZYadWR0opyZt/2kE8V03Ly+jrx89PaoI+UA9EVn1gmADhbV08HXcFE1YhgL9SIutdVhLb/jr919it+wNnB4m5lZMXKnbdUc3mZmVozcmK6aw9vMzIpxy7tyDm8zMyvGLe/KObzNzKyYnt6qa7DYc3ibmVkx7javnMPbzMyKcbd55RzeZmZWjFvelXN4DwGS3grsC6ydBz0JjI+IB6qrlZlZE255V86HTxWT9E3gQkDAHfkhYJyko6qsm5lZQz29rT+sLdzyrt5BwNsiYk7tQEknApOA7zWbUdIYYAzAsPV2Y9hqb29nPc3MEnebV87vQPX6gLUaDF8zj2sqIsZGxKiIGOXgNrOOUU/rD2sLt7yr92XgOkmPAFPzsPWAjYDDKquVmVkz/nGYyjm8KxYRV0naBNiW+S9YmxAR86qrmZlZE25RV87hPQRERB9wW9X1MDNria82r5zD28zMivFV5JVzeJuZWTHuNq+cw9vMzIpxt3nlHN5mZlaMW96Vc3ibmVkxbnlXzuG9iJh52086Us5K23Tuq+czJ5zSsbJ6/b1Va2BeX3SknK7b/nzBWuUc3mZmVoy7zSvn8DYzs2Ic3pVzeJuZWTE+5105h7eZmRXjlnflHN5mZlaMW96Vc3ibmVkxvtq8cg5vMzMrRG55V87hbWZmhTi8q+erDszMrBgVeLSyOGkPSQ9JmiLpqAbj15N0vaS7Jf1F0vvLWZHu5fA2M7NCJLX8aGFZvcCpwJ7ASOAASSPrJvsv4KKI2AoYDfys5FXqOg7vIU7SZwYYN0bSREkTzzx9bCerZWaLsTLDG9gWmBIRj0bEbOBCYN+6aQJYPv+9AjC9tJXpUj7nPfQdB5zdaEREjAXGArw+l87chNnMFns9PaW2+9YGptY8nwZsVzfNscA1kg4HlgF2L7MC3cjhPQRI+kuzUcAanayLmdmgClyvJmkMMKZm0Njc8CjiAOAXEfFjSe8EzpO0WUT0FVzOIsPhPTSsAfw7MLNuuIA/db46ZmbNFbnavLaHsIkngXVrnq+Th9U6CNgjL+/PkkYAqwLPtFyRRYzDe2i4Alg2Iu6pHyHphs5Xx8ysuZK/KjYB2FjShqTQHg18rG6aJ4DdgF9I2hQYATxbZiW6jcN7CIiIgwYYV78Rm5lVqszwjoi5kg4DrgZ6gbMiYpKk44GJETEe+CpwuqQjSRevfToiFuvrfBzeZmZWiHrKvUlLRFwJXFk37OiavycDO5ZaaJdzeJuZWSG+w1r1HN5mZlaIw7t6Dm8zMyvE4V09h7eZmRXj7K6cw3sR0dfXmQsvZ044pSPlAKy07/92rKynLz2sI+UsMaxzdyTu6WTrqINFdWpbt+bc8q6ew9vMzAop+faotgAc3mZmVohb3tVzeJuZWTHO7so5vM3MrBC3vKvn8DYzs0Ic3tVzeJuZWSEO7+o5vM3MrJCy721uxTm8zcysELe8q+fwNjOzQhze1fM37YcISW+VtJukZeuG71FVnczMGpHU8sPaw+E9BEj6EvAb4HDgfkn71oz+7wHmGyNpoqSJZ50xtt3VNDNLVOBhbeFu86HhEOAdEfGKpA2ASyRtEBEnMcDmHxFjgbEAs2aHb/hsZh3h26NWz+E9NPRExCsAEfGYpF1JAb4+PnY1syHGveHV8+HT0PC0pC37n+Qg3xtYFXh7ZbUyM2vA57yr5/AeGj4F/L12QETMjYhPATtXUyUzs8ak1h/WHu42HwIiYtoA427tZF3MzAbjFnX1HN5mZlaIs7t6Dm8zMyukt9fpXTWHt5mZFeJu8+o5vM3MrBBnd/Uc3lZIX1/n7gXz5EVf7FhZa3z05x0ra8Ylh3asrOdfnd2xslZYenhHyuldBJNjXl/Q18H7LI0YtnBfNHLLu3oOb7MOcnBbI50M7jI4vKvn8DYzs0Kc3dVzeJuZWSE9PU7vqjm8zcysEHebV8/hbWZmhTi7q+fwNjOzQtzyrp7D28zMCnF2V8/hbWZmhfiCteo5vM3MrBB3m1fP4T1ESNoWiIiYIGkksAfwYERcWXHVzMzm4+yunsN7CJB0DLAnMEzStcB2wPXAUZK2iojvVlpBM7MabnlXb+FucGtl2Q/YEdgZ+CLwwYg4Afh3YP9mM0kaI2mipIlnnTG2MzU1s8We1PqjteVpD0kPSZoi6agm03xU0mRJkyRdUOb6dCO3vIeGuRExD5gl6a8R8RJARLwmqa/ZTBExFhgLMGt2l90c2cy6Vpktb0m9wKnAe4FpwARJ4yNics00GwPfAnaMiJmSVi+tAl3KLe+SSfqBpOUlDZd0naRnJX1ikNlmS1o6//2OmmWtADQNbzOzKvT0qOVHC7YFpkTEoxExG7gQ2LdumkOAUyNiJkBEPFPqCnUhh3f53pdbznsDjwEbAV8fZJ6dI2IWQETUhvVw4MB2VNLMbEFJKvJ44/RefoypW9zawNSa59PysFqbAJtIulXSbZL2aOf6dQN3m5ev/zXdC7g4Il4crIspIv7RZPhzwHPlVs/MbOEU6TWvPb23EIYBGwO7AusAN0l6e0S8sJDL7VoO7/JdIelB4DXg85JWA16vuE5mZqUp+WrzJ4F1a56vk4fVmgbcHhFzgL9JepgU5hPKrEg3cbd5ySLiKGAHYFTe0Gbxz+dvzMy6VslXm08ANpa0oaQlgNHA+LppLie1upG0Kqkb/dHSVqgLObxLli88+wLwf3nQWsCo6mpkZlau3h61/BhMRMwFDgOuBh4ALoqISZKOl7RPnuxqYIakyaR7YHw9Ima0afW6grvNy3c2cCep9Q2p++di4IrKamRmVqKyb9KS7yR5Zd2wo2v+DuAr+WG45d0O/xYRPwDmAOSryH07IjNbZPSo9Ye1h1ve5ZstaSkgACT9G9DwavJu1MlfExoxvHPHljMv+3xHyllph691pByAGbf+sGNlzevzPYIWxutzOns7h+WWXLjPlm+PWj2Hd/mOAa4C1pX0S9JtTz9daY3MzErk7K6ew7tkEXGtpLuA7Und5Ufk72ubmS0S5DOBlXN4l0zSzvnPl/P/IyURETdVVSczszK1chW5tZfDu3y1t0IdQbpv753Ae6qpjplZudxtXj2Hd8ki4gO1zyWtC/y0ouqYmZWux+ldOYd3+00DNq26EmZmZXF2V8/hXTJJJ5O/Jkb6Hv2WwF3V1cjMrFz+qlj1HN7lm1jz91xgXETcWlVlzMzK5uyunsO7ZBFxTtV1MDNrp16nd+Uc3iWRdB9vdpfPN4p0a97NCyzr3Ij4VGmVMzMrkbvNq+fwLs/eCzKTpPqfvhPwbkkrAkTEPv88l5lZdfw17+o5vEsSEY8v4KzrAJOBM0gtd5F+QvTHg80oaQwwBuDkU0/jswePWcAqmJm1zi3v6jm8SyZpe+Bk0tfDlgB6gVcjYvkms4wCjgC+TfqN2nskvRYRNw5WVkSMBcYCzJod/mUIM+sIZ3f1HN7lOwUYTfoN71HAp4BNmk0cEX3ATyRdnP9/Gr8vZjaE+fao1XNItEFETJHUGxHzgLMl3Q18a5B5pgH/IWkv4KVO1NPMbEG427x6Du/yzZK0BHCPpB8AT5Fu1tKSiPgd8Lt2Vc7MbGE5uqu3cL/Ibm+QtE3+85Ok1/Uw4FVgXeAjVdXLzKxsPVLLD2sPt7zLM1bSssCFpLuqTQaOq7hOZmalcyZXzy3vkkTEVqTves8FLpF0r6SjJG1QacXMzEomqeWHtYfDu0QR8VBEHBcRI0lXma8AXCfJ9zY3s0VGb49aflh7uNu8DST1AKsDawDLAM9UWyMzs/K4QV09h3eJJO0EHAB8ELiPdP77yIh4sdKKdameDh61P/fy7I6UM/NPP+pIOQBv++bvO1bWff+zR8fK6uR2MXtuX0fKWW5Ed+2K3R1eve7aYoYwSVOBx0mBfWxEuLVtZoskn2+tnsO7PO9aiPubm5l1Dbe8q+fwLomD28wWF74OrXoObzMzK8RXkVfP4W1mZoU4u6vn8C6JpJNJv8fdUER8qYPVMTNrG5/yrp7DuzwTq66AmVkn+J7l1XN4lyQizqm6DmZmneCvilXP4V0ySasB3wRGAiP6h0fEeyqrlJlZiXzBWvV8AFW+XwIPABuSflXsMWBCkQVIepekr0h6X/nVMzNbOFLrD2sPh3f5VomIM4E5EXFjRHwWGLDVLemOmr8PAU4BlgOOkXTUAPONkTRR0sSzzhhbUvXNzAbWo9Yf1h7uNi/fnPz/U5L2AqYDKw8yz/Cav8cA742IZyX9CLgN+F6jmSJiLDAWYNbsaHqlu5lZmXzBWvUc3uX7jqQVgK8CJwPLA0cOMk+PpJVIPSGKiGcBIuJVSXPbWlszs4Kc3dVzt3nJIuKKiHgxIu6PiHdHxDsiYvwgs60A3En6utnKktYEkLQs4I+JmQ0pZXebS9pD0kOSpgxyqvAjkkLSqLLWpVu55V0ySWfT4GYt+dx3QxGxQZNRfcCHyqmZmVk5ektsekvqBU4F3gtMAyZIGh8Rk+umWw44Ari9tMK7mMO7fFfU/D2CFL7TF2RBETEL+FsZlTIzK0vJF6JtC0yJiEcBJF0I7AtMrpvuBOD7wNdLLb1LObxLFhGX1j6XNA64paLqmJmVrshPgkoaQ7oQt9/YfLFtv7WBqTXPpwHb1S1ja2DdiPidJIc3Du9O2BhYvepKmJmVpUjLu/ZbMQtCUg9wIruxTsoAABHqSURBVPDpBV3GosjhXTJJLzP/Oe+/k+64Zma2SCj5avMngXVrnq+Th/VbDtgMuCG3+P8FGC9pn4hYbH9TwuFdsohYruo6mJm1U8nf854AbCxpQ1JojwY+1j8yIl4EVu1/LukG4GuLc3CDvypWOknXtTLMzKxb9fa0/hhMRMwFDgOuJt1a+qKImCTpeEn7tHdNupfCN+YqhaQRwNLA9cCuvPn97OWBqyLire0s//W5zX9LvFv9Y05fx8pacnhnjmP7+jr3Ns3tYFlr7PPjjpU180pfr7SwRgxbuPtHnHrrYy1vXF/ccQPfq6IN3G1ens8BXwbWIt1wpX+DfYl0r3Izs0WC77BWPYd3SSLiJOAkSYdHxMlV18fMrF38gyPV8znv8vVJWrH/iaSVJH2hygqZmZWpR2r5Ye3h8C7fIRHxQv+TiJgJHFJhfczMStXbo5Yf1h7uNi9fryRFvhIw37d3iYrrZGZWGjeoq+fwLt9VwK8k/Tw//1weZma2SHCXbfUc3uX7Juk+vp/Pz68FTq+uOmZm5Spyb3NrDx9AlSwi+iLitIjYLyL2I/0yjq8+N7NFhgo8rD3c8m4DSVsBBwAfJf2k52XV1sjMrDy+irx6Du+SSNqEFNgHAM8BvyLdwe7dLcy7HfBARLwkaSngKGBrUqv9v/O9fc3MhgRfRF49d5uX50HgPcDeEfGufKOWeS3OexYwK/99ErAC6UfnZwFnN5tJ0hhJEyVNPPP0Bf7FPTOzQiS1/LD2cMu7PB8m/RrO9ZKuAi6k9VM+Pfnm/ACjImLr/Pctku5pNlPt7+Quivc2N7Ohya2+6vk9KElEXB4Ro4G3kn6c5MvA6pL+T9L7Bpn9fkmfyX/fK2kUvNEVP6dtlTYzWwBueVfP4V2yiHg1Ii6IiA+QflT+btLXxwZyMLCLpL8CI4E/S3qU9BWzg9taYTOzgny1efXcbd5G+daob3RtDzDdi8CnJS0PbEh6X6ZFxNPtr6WZWTFuUVfP4T2ERMRLwL1V18PMbCC9Du/KObzNzKwQR3f1HN5mZlaIG97Vc3ibmVkhPW57V87hbWZmhbjlXT2HtxUyZ25f1VXoaj09oq+vM/fTWWJY574JOuOKr3WsrJV2OqpjZT134/90rKw58zr32RoxrHeh5ve9zavn8DbroE4Ft3WXTgZ3GdxtXj2Ht5mZFeKGd/Uc3mZmVojDu3oObzMzK0TuNq+cw9vMzArx73lXz+FtZmaF+Grz6jm8zcysEHebV8/hbWZmhbjbvHoObzMzK8Qt7+p17hZM1pSkL0lat+p6mJm1Qmr9Ye3h8B4aTgBul3SzpC9IWq3qCpmZNdMrtfyw9nB4Dw2PAuuQQvwdwGRJV0k6UNJyzWaSNEbSREkTzzx9bKfqamaLORV4WHv4nPfQEBHRB1wDXCNpOLAncADwI6BhSzwixgJjAV6fi2+abWad4VSunMN7aJjvoxARc4DxwHhJS1dTJTOzxnzBWvUc3kPD/s1GRMSsTlbEzGwwPpVdPYf3EBARD1ddBzOzVjm7q+cL1szMrBBJLT9aXN4ekh6SNEXSUQ3Gf0XSZEl/kXSdpPVLX6ku4/A2M7NCyvyet6Re4FTSRbojgQMkjayb7G5gVERsDlwC/KDcNeo+Dm8zMyuk5K+KbQtMiYhHI2I2cCGwb+0EEXF9zfU/t5G+WrtYc3ibmVkxBdK79n4U+TGmbmlrA1Nrnk/Lw5o5CPh9OSvSvXzBmpmZFVLkq2K196NY6HKlTwCjgF3KWF43c3gvIvr6OnOPluHDOtdZ06l1ApjXobJ6O/hzTE+98HrHylp1uSU6VtYz1/93x8padd+fdqScZy4/oiPllKXkr4o9CdT+tsM6eVhdmdod+DawS0T8o9QadCF3m5uZWSEl/zDJBGBjSRtKWgIYTbpJVU152gr4ObBPRDxT9vp0I7e8zcyskDLvsBYRcyUdBlwN9AJnRcQkSccDEyNiPPBDYFng4vz1syciYp/SKtGFHN5mZlZI2XdYi4grgSvrhh1d8/fu5ZbY/RzeZmZWiO+wVj2Ht5mZFeP0rpzD28zMCunxL5NUzuFtZmaFOLqr5/A2M7NinN6Vc3ibmVkhZX5VzBaMw7tiNTclmB4Rf5D0MWAH4AFgbETMqbSCZmZ1fMq7eg7v6p1Neh+WlnQg6UYElwG7kX5t58AK62Zm9k+c3dVzeFfv7RGxuaRhpPv5rhUR8ySdD9w70Iz513nGAJx86ml89uD6H+sxMyuf3PSunMO7ej2563wZYGlgBeB5YElg+EAz1v5az6zZ0blf8TCzxZqzu3oO7+qdCTxIuqfvt0n37n0U2J70o/RmZkOKs7t6Du+KRcRPJP0q/z1d0rnA7sDpEXFHtbUzM2vA6V05h/cQEBHTa/5+AbikwuqYmQ3IXxWrnsPbzMwK8Tnv6jm8zcysEId39RzeZmZWiLvNq+fwNjOzQtzyrp7D28zMCnF2V0/he3ssEl6fS0feyL6+zm0vPT2L3i5izty+jpXV29u516+Tv+/cyW1wbofKWmO/n3WknH6vXXHYQr1h02b+o+UXZp2Vllz0PshDgFveZmZWiG+PWj2Ht5mZFeLorp7D28zMCnHDu3oObzMzK8RfFauew9vMzIpxdlfO4W1mZoU4u6vn8DYzs0I6+dVAa8zhbWZmxTi7K+fwNjOzQpzd1XN4DwGS/hX4MLAuMA94GLggIl6qtGJmZg2417x6PVVXYHEn6UvAacAIYBtgSVKI3yZp10HmHSNpoqSJZ54+tu11NTOD9FWxVv9Ze7jlXb1DgC0jYp6kE4ErI2JXST8HfgNs1WzGiBgLjIXO3dvczMwt7+o5vIeGYaTu8iWBZQEi4glJwyutlZlZAw7v6jm8q3cGMEHS7cBOwPcBJK0GPF9lxczMGnF3ePUc3hWLiJMk/QHYFPhxRDyYhz8L7Fxp5czMGnDLu3oO7yEgIiYBk6quh5lZK5zd1XN4m5lZMU7vyjm8zcysEN8etXr+nreZmRWiAo+WliftIekhSVMkHdVg/JKSfpXH3y5pgxJWo6s5vM3MrJgS01tSL3AqsCcwEjhA0si6yQ4CZkbERsBPyN/KWZw5vM3MrJCS77C2LTAlIh6NiNnAhcC+ddPsC5yT/74E2E1avPvufc57ETFiWPFLSCSNyXdpKzJX0WIWoqwFM5TLGjFswY6Xh/I6db6sTm6DnSnrtSsO60g5ZVlqeOsvjKQxwJiaQWPr6rw2MLXm+TRgu7rFvDFNRMyV9CKwCvBckXovStzyXryNGXwSlzVEyloU18lldU85CywixkbEqJqHf4ihBA5vMzOr0pOkH2Pqt04e1nAaScOAFYAZHandEOXwNjOzKk0ANpa0oaQlgNHA+LppxgMH5r/3A/4YEYv1jzH5nPfirZPdVy6rO8pxWd1VVtd3Qedz2IcBVwO9wFkRMUnS8cDEiBgPnAmcJ2kK6TcfRldX46FBi/nBi5mZWddxt7mZmVmXcXibmZl1GYf3Ymqw2xGWWM5Zkp6RdH+7ysjlrCvpekmTJU2SdEQbyxoh6Q5J9+ayjmtXWTVl9kq6W9IVbS7nMUn3SbpH0sQ2l7WipEskPSjpAUnvbEMZb8nr0v94SdKXyy6nprwj8zZxv6Rxkka0sawjcjmT2rlONjT5nPdiKN+O8GHgvaQbIkwADoiIyW0oa2fgFeDciNis7OXXlLMmsGZE3CVpOeBO4INtWicBy0TEK5KGA7cAR0TEbWWXVVPmV4BRwPIRsXcby3kMGBURbb/5haRzgJsj4ox8lfHSEfFCG8vrJX3laLuIeLwNy1+btC2MjIjXJF0EXBkRv2hDWZuR7kS2LTAbuAo4NCKmlF2WDU1ueS+eWrkdYSki4ibS1aFtFRFPRcRd+e+XgQdId2VqR1kREa/kp8Pzo21HwZLWAfYCzmhXGZ0maQVgZ9JVxETE7HYGd7Yb8Nd2BHeNYcBS+bvISwPT21TOpsDtETErIuYCNwIfblNZNgQ5vBdPjW5H2Jagq0L+xaGtgNvbWEavpHuAZ4BrI6JtZQE/Bb4B9LWxjH4BXCPpznxby3bZEHgWODufDjhD0jJtLA/S14vGtWvhEfEk8CPgCeAp4MWIuKZNxd0P7CRpFUlLA+9n/hud2CLO4W2LFEnLApcCX46Il9pVTkTMi4gtSXeD2jZ3Y5ZO0t7AMxFxZzuW38C7ImJr0i88fTGf9miHYcDWwP9FxFbAq0A7r71YAtgHuLiNZaxE6sHaEFgLWEbSJ9pRVkQ8QPplrWtIXeb3APPaUZYNTQ7vxVMrtyPsOvn886XALyPisk6Umbt6rwf2aFMROwL75HPRFwLvkXR+m8rqbz0SEc8AvyadYmmHacC0mh6LS0hh3i57AndFxNNtLGN34G8R8WxEzAEuA3ZoV2ERcWZEvCMidgZmkq5jscWEw3vx1MrtCLtKvojsTOCBiDixzWWtJmnF/PdSpAv/HmxHWRHxrYhYJyI2IL1Pf4yItrTmJC2TL/Yjd2G/j9Q9W7qI+DswVdJb8qDdgNIvLqxxAG3sMs+eALaXtHTeHncjXXvRFpJWz/+vRzrffUG7yrKhx7dHXQw1ux1hO8qSNA7YFVhV0jTgmIg4sw1F7Qh8Ergvn4sG+M+IuLINZa0JnJOvXu4BLoqItn6Fq0PWAH6dfyZ5GHBBRFzVxvIOB36ZDyAfBT7TjkLygch7gc+1Y/n9IuJ2SZcAdwFzgbtp7+1LL5W0CjAH+GIHLvizIcRfFTMzM+sy7jY3MzPrMg5vMzOzLuPwNjMz6zIObzMzsy7j8DYzM+syDm8zM7Mu4/A2MzPrMg5vMzOzLuPwNjMz6zIObzMzsy7j8DYzM+syDm8zM7Mu4/A2MzPrMg5vMzOzLuPwNjMz6zIObzMzsy7j8DZbQJLmSbpH0v2SLpa09EIs6xeS9st/nyFp5ADT7ipphwUo4zFJq9YNO1vS5+qGfVDS71upq5lVw+FttuBei4gtI2IzYDZwaO1IScMWZKERcXBETB5gkl2BwuHdxDhgdN2w0Xm4mQ1RDm+zctwMbJRbxTdLGg9MltQr6YeSJkj6S38rV8kpkh6S9Adg9f4FSbpB0qj89x6S7pJ0r6TrJG1AOkg4Mrf6d5K0mqRLcxkTJO2Y511F0jWSJkk6A1CDel8HvFXSmnmeZYDdgcslHZ2Xd7+ksZL+af7a1rykUZJu6F+OpLMk3SHpbkn75uFvy8Puya/HxiW89maLHYe32ULKLew9gfvyoK2BIyJiE+Ag4MWI2AbYBjhE0obAh4C3ACOBT9GgJS1pNeB04CMRsQXwHxHxGHAa8JPc6r8ZOCk/3wb4CHBGXsQxwC0R8Tbg18B69WVExDzgUuCjedAHgBsi4iXglIjYJvcsLAXsXeBl+Tbwx4jYFng38MN8YHAocFJEbAmMAqYVWKaZZQvUrWdmACwl6Z78983AmaQQviMi/paHvw/YvOYc8QrAxsDOwLgcntMl/bHB8rcHbupfVkQ836QeuwMjaxrGy0taNpfx4Tzv7yTNbDL/OOBHpIOA0cB5efi7JX0DWBpYGZgE/LbJMuq9D9hH0tfy8xGkg4c/A9+WtA5wWUQ80uLyzKyGw9tswb2WW5BvyAH6au0g4PCIuLpuuveXWI8eYPuIeL1BXVrxJ2BNSVuQDj5GSxoB/AwYFRFTJR1LCuB6c3mzB692vEg9Bg/VTf+ApNuBvYArJX0uIhoduJjZANxtbtZeVwOflzQcQNImufv4JmD/fE58TVLXcr3bgJ1zNzuSVs7DXwaWq5nuGuDw/ieS+g8obgI+loftCazUqIIREcCvgHOA3+eDgP4gfi634ptdXf4Y8I7890fq1vvw/vPkkrbK//8r8GhE/C/wG2DzJss1swE4vM3a6wxgMnCXpPuBn5N6vH4NPJLHnUvqTp5PRDwLjAEuk3QvKWAhdV1/qP+CNeBLwKh8Adhk3rzq/ThS+E8idZ8/MUA9xwFb5P+JiBdI59vvJwXxhCbzHQecJGkiMK9m+AnAcOAvufwT8vCPAvfn0w2b5XU3s4KUDrrNzMysW7jlbWZm1mUc3mZmZl3G4W1mZtZlHN5mZmZdxuFtZmbWZRzeZmZmXcbhbWZm1mUc3mZmZl3m/wPCeYjK4iI4wAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conv LSTM"
      ],
      "metadata": {
        "id": "4A13558LTO1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import TensorBoard\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "timesteps = 20\n",
        "width = 34\n",
        "height = 34\n",
        "channels = 1\n",
        "action_num = 10\n",
        "\n",
        "model = models.Sequential(\n",
        "    [\n",
        "        layers.Input(\n",
        "            shape=(timesteps, width, height, channels)\n",
        "        ),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True, dropout=0.1, recurrent_dropout=0.1\n",
        "        ),\n",
        "        layers.MaxPool3D(\n",
        "            pool_size=(1, 2, 2), strides=(1, 2, 2), padding=\"same\"\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=32, kernel_size=(3, 3), padding=\"same\", return_sequences=True, dropout=0.1, recurrent_dropout=0.1\n",
        "        ),\n",
        "        layers.MaxPool3D(\n",
        "            pool_size=(1, 2, 2), strides=(1, 2, 2), padding=\"same\"\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=16, kernel_size=(3, 3), padding=\"same\", return_sequences=False, dropout=0.1, recurrent_dropout=0.1\n",
        "        ),\n",
        "        layers.MaxPool2D(\n",
        "            pool_size=(2, 2), strides=(2, 2), padding=\"same\"\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(action_num, activation='softmax')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n",
        "logdir = \"logs/NMNIST_ConvLSTM\"\n",
        "# Training  the model along with creating callbacks to tensorboard for graphical visualization of training process\n",
        "tbcallback = keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=40, validation_data=(x_val, y_val), callbacks=[early_stopping, tbcallback])"
      ],
      "metadata": {
        "id": "iQ37PqG4THui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e62b5e-7450-4595-e6a0-e4f8b6a7ff93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75/75 [==============================] - 35s 382ms/step - loss: 2.2404 - accuracy: 0.1967 - val_loss: 2.3011 - val_accuracy: 0.1050\n",
            "Epoch 2/40\n",
            "75/75 [==============================] - 28s 375ms/step - loss: 1.8606 - accuracy: 0.3600 - val_loss: 2.2871 - val_accuracy: 0.1033\n",
            "Epoch 3/40\n",
            "75/75 [==============================] - 28s 369ms/step - loss: 1.5679 - accuracy: 0.4854 - val_loss: 2.2010 - val_accuracy: 0.2450\n",
            "Epoch 4/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 1.2941 - accuracy: 0.5717 - val_loss: 2.0215 - val_accuracy: 0.3200\n",
            "Epoch 5/40\n",
            "75/75 [==============================] - 28s 371ms/step - loss: 1.1081 - accuracy: 0.6283 - val_loss: 1.6978 - val_accuracy: 0.4800\n",
            "Epoch 6/40\n",
            "75/75 [==============================] - 28s 371ms/step - loss: 0.9836 - accuracy: 0.6871 - val_loss: 1.3598 - val_accuracy: 0.5850\n",
            "Epoch 7/40\n",
            "75/75 [==============================] - 28s 373ms/step - loss: 0.8761 - accuracy: 0.7196 - val_loss: 1.1703 - val_accuracy: 0.6400\n",
            "Epoch 8/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.7995 - accuracy: 0.7421 - val_loss: 0.9884 - val_accuracy: 0.6967\n",
            "Epoch 9/40\n",
            "75/75 [==============================] - 28s 371ms/step - loss: 0.7299 - accuracy: 0.7733 - val_loss: 0.9371 - val_accuracy: 0.7050\n",
            "Epoch 10/40\n",
            "75/75 [==============================] - 28s 369ms/step - loss: 0.6680 - accuracy: 0.7817 - val_loss: 0.9012 - val_accuracy: 0.6967\n",
            "Epoch 11/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.6245 - accuracy: 0.7987 - val_loss: 0.9222 - val_accuracy: 0.6900\n",
            "Epoch 12/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.5877 - accuracy: 0.8229 - val_loss: 0.8538 - val_accuracy: 0.7250\n",
            "Epoch 13/40\n",
            "75/75 [==============================] - 29s 381ms/step - loss: 0.5436 - accuracy: 0.8317 - val_loss: 0.8374 - val_accuracy: 0.7150\n",
            "Epoch 14/40\n",
            "75/75 [==============================] - 28s 371ms/step - loss: 0.4983 - accuracy: 0.8438 - val_loss: 0.8360 - val_accuracy: 0.7367\n",
            "Epoch 15/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.4640 - accuracy: 0.8550 - val_loss: 0.8405 - val_accuracy: 0.7167\n",
            "Epoch 16/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.4542 - accuracy: 0.8517 - val_loss: 0.8272 - val_accuracy: 0.7267\n",
            "Epoch 17/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.4282 - accuracy: 0.8729 - val_loss: 0.8251 - val_accuracy: 0.7233\n",
            "Epoch 18/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.3954 - accuracy: 0.8750 - val_loss: 0.8171 - val_accuracy: 0.7383\n",
            "Epoch 19/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.3737 - accuracy: 0.8908 - val_loss: 0.7987 - val_accuracy: 0.7433\n",
            "Epoch 20/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.3383 - accuracy: 0.9017 - val_loss: 0.8202 - val_accuracy: 0.7433\n",
            "Epoch 21/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.3245 - accuracy: 0.9033 - val_loss: 0.8263 - val_accuracy: 0.7300\n",
            "Epoch 22/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.3043 - accuracy: 0.9162 - val_loss: 0.8042 - val_accuracy: 0.7383\n",
            "Epoch 23/40\n",
            "75/75 [==============================] - 28s 371ms/step - loss: 0.2898 - accuracy: 0.9171 - val_loss: 0.7962 - val_accuracy: 0.7517\n",
            "Epoch 24/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.2742 - accuracy: 0.9221 - val_loss: 0.8050 - val_accuracy: 0.7417\n",
            "Epoch 25/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.2564 - accuracy: 0.9217 - val_loss: 0.7816 - val_accuracy: 0.7483\n",
            "Epoch 26/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.2402 - accuracy: 0.9292 - val_loss: 0.7573 - val_accuracy: 0.7633\n",
            "Epoch 27/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.2279 - accuracy: 0.9325 - val_loss: 0.7812 - val_accuracy: 0.7667\n",
            "Epoch 28/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.2183 - accuracy: 0.9362 - val_loss: 0.7674 - val_accuracy: 0.7633\n",
            "Epoch 29/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.2023 - accuracy: 0.9438 - val_loss: 0.8348 - val_accuracy: 0.7500\n",
            "Epoch 30/40\n",
            "75/75 [==============================] - 28s 370ms/step - loss: 0.1940 - accuracy: 0.9508 - val_loss: 0.8418 - val_accuracy: 0.7567\n",
            "Epoch 31/40\n",
            "75/75 [==============================] - 28s 369ms/step - loss: 0.1924 - accuracy: 0.9463 - val_loss: 0.8028 - val_accuracy: 0.7567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/MyDrive/models/conv_lstm_nmnist_recon.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "# del model  # deletes the existing model"
      ],
      "metadata": {
        "id": "X1oMxFA2B9RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results"
      ],
      "metadata": {
        "id": "JjJ5D79PB9RU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/models/conv_lstm_nmnist_recon.h5')"
      ],
      "metadata": {
        "id": "Xj6rToVGB9RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "y_pred = model.predict(x_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ktcrqI8UFNd",
        "outputId": "198cdbb2-22f5-4735-cd12-ca7d444da42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.6660446524620056\n",
            "Test accuracy: 0.7960000038146973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIs9hf-cB9RV",
        "outputId": "dcec93f7-790a-4a57-b663-5bfc3f39b38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.87        75\n",
            "           1       0.96      0.96      0.96        75\n",
            "           2       0.82      0.91      0.86        75\n",
            "           3       0.77      0.57      0.66        75\n",
            "           4       0.74      0.72      0.73        75\n",
            "           5       0.67      0.71      0.69        75\n",
            "           6       0.88      0.85      0.86        75\n",
            "           7       0.85      0.84      0.85        75\n",
            "           8       0.74      0.64      0.69        75\n",
            "           9       0.71      0.84      0.77        75\n",
            "\n",
            "    accuracy                           0.80       750\n",
            "   macro avg       0.80      0.80      0.79       750\n",
            "weighted avg       0.80      0.80      0.79       750\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import seaborn as sns\n",
        "\n",
        "#Create confusion matrix and normalizes it over predicted (columns)\n",
        "result = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), normalize='pred')\n",
        "\n",
        "ax = sns.heatmap(result, annot=False, cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix for Reconstructed NMNIST Classification with ConvLSTM Network\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([i for i in range(10)])\n",
        "ax.yaxis.set_ticklabels([i for i in range(10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "jzvNV6fyB9RV",
        "outputId": "b841aa4b-20b5-4737-a5b7-d60318388d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0.5, '0'),\n",
              " Text(0, 1.5, '1'),\n",
              " Text(0, 2.5, '2'),\n",
              " Text(0, 3.5, '3'),\n",
              " Text(0, 4.5, '4'),\n",
              " Text(0, 5.5, '5'),\n",
              " Text(0, 6.5, '6'),\n",
              " Text(0, 7.5, '7'),\n",
              " Text(0, 8.5, '8'),\n",
              " Text(0, 9.5, '9')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom LTSM Network 1"
      ],
      "metadata": {
        "id": "cEW0X1XZmcSW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTy0bv9iTjxD"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "\n",
        "def build_convnet(shape=(34, 34, 1)):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(128, (2,2), padding='same', input_shape=shape))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  model.add(Conv2D(256, (2,2), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  model.add(Conv2D(512, (2,2), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  # model.add(Conv2D(64, (9,9), padding='same'))\n",
        "  # model.add(Activation('relu'))\n",
        "\n",
        "  # model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # model.add(Dense(512))\n",
        "  # model.add(Activation('relu'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaQRLi4QNRXL"
      },
      "outputs": [],
      "source": [
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.layers import TimeDistributed, GRU\n",
        "\n",
        "def action_model(shape=(20, 34, 34, 1), nbout=10):\n",
        "    # Create our convnet with (34, 34, 1) input shape\n",
        "    print(\"done\")\n",
        "    convnet = build_convnet(shape[1:])\n",
        "\n",
        "    # then create our final model\n",
        "    model = Sequential()\n",
        "    # add the convnet with (8, 34, 34, 1) shape\n",
        "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "    # here, you can also use GRU or LSTM\n",
        "    model.add(GRU(64))\n",
        "    # and finally, we make a decision network\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(nbout, activation='softmax'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS6id-x9Re7i",
        "outputId": "f7b7ed1d-db91-4e61-c435-0acf877b9b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_1 (TimeDis  (None, 20, 8192)         656768    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 64)                1585536   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1024)              66560     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,908,234\n",
            "Trainable params: 2,908,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "75/75 [==============================] - 8s 92ms/step - loss: 2.3023 - accuracy: 0.1083 - val_loss: 2.3019 - val_accuracy: 0.0967\n",
            "Epoch 2/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 2.3016 - accuracy: 0.1037 - val_loss: 2.2972 - val_accuracy: 0.2000\n",
            "Epoch 3/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 2.2888 - accuracy: 0.1367 - val_loss: 2.2472 - val_accuracy: 0.1700\n",
            "Epoch 4/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 2.2194 - accuracy: 0.1733 - val_loss: 2.1102 - val_accuracy: 0.2533\n",
            "Epoch 5/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 2.0516 - accuracy: 0.2429 - val_loss: 1.8005 - val_accuracy: 0.3467\n",
            "Epoch 6/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 1.7283 - accuracy: 0.3512 - val_loss: 1.4552 - val_accuracy: 0.4967\n",
            "Epoch 7/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 1.5012 - accuracy: 0.4346 - val_loss: 1.2896 - val_accuracy: 0.5383\n",
            "Epoch 8/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 1.3721 - accuracy: 0.4963 - val_loss: 1.2569 - val_accuracy: 0.5533\n",
            "Epoch 9/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 1.2785 - accuracy: 0.5221 - val_loss: 1.1421 - val_accuracy: 0.5917\n",
            "Epoch 10/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 1.1788 - accuracy: 0.5771 - val_loss: 1.0619 - val_accuracy: 0.6400\n",
            "Epoch 11/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 1.1142 - accuracy: 0.5954 - val_loss: 1.1050 - val_accuracy: 0.6033\n",
            "Epoch 12/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 1.0223 - accuracy: 0.6229 - val_loss: 0.9384 - val_accuracy: 0.6700\n",
            "Epoch 13/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.9584 - accuracy: 0.6500 - val_loss: 0.9056 - val_accuracy: 0.6883\n",
            "Epoch 14/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.8819 - accuracy: 0.6800 - val_loss: 0.9396 - val_accuracy: 0.6933\n",
            "Epoch 15/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.8214 - accuracy: 0.7075 - val_loss: 0.8271 - val_accuracy: 0.7250\n",
            "Epoch 16/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 0.7520 - accuracy: 0.7287 - val_loss: 0.8272 - val_accuracy: 0.7350\n",
            "Epoch 17/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 0.7059 - accuracy: 0.7475 - val_loss: 0.7992 - val_accuracy: 0.7517\n",
            "Epoch 18/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 0.6472 - accuracy: 0.7721 - val_loss: 0.7873 - val_accuracy: 0.7567\n",
            "Epoch 19/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 0.6208 - accuracy: 0.7792 - val_loss: 0.7487 - val_accuracy: 0.7683\n",
            "Epoch 20/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.5707 - accuracy: 0.7954 - val_loss: 0.7708 - val_accuracy: 0.7517\n",
            "Epoch 21/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.5302 - accuracy: 0.8133 - val_loss: 0.6781 - val_accuracy: 0.7950\n",
            "Epoch 22/60\n",
            "75/75 [==============================] - 6s 84ms/step - loss: 0.4968 - accuracy: 0.8346 - val_loss: 0.7655 - val_accuracy: 0.7683\n",
            "Epoch 23/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.4526 - accuracy: 0.8462 - val_loss: 0.6932 - val_accuracy: 0.8000\n",
            "Epoch 24/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 0.4169 - accuracy: 0.8596 - val_loss: 0.6738 - val_accuracy: 0.7833\n",
            "Epoch 25/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 0.3694 - accuracy: 0.8767 - val_loss: 0.7232 - val_accuracy: 0.7900\n",
            "Epoch 26/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 0.3320 - accuracy: 0.8913 - val_loss: 0.7049 - val_accuracy: 0.7983\n",
            "Epoch 27/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.3633 - accuracy: 0.8746 - val_loss: 0.6748 - val_accuracy: 0.8100\n",
            "Epoch 28/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.2823 - accuracy: 0.9025 - val_loss: 0.6813 - val_accuracy: 0.8117\n",
            "Epoch 29/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.2550 - accuracy: 0.9117 - val_loss: 0.6911 - val_accuracy: 0.8133\n",
            "Epoch 30/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.2253 - accuracy: 0.9292 - val_loss: 0.7225 - val_accuracy: 0.8167\n",
            "Epoch 31/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.2288 - accuracy: 0.9233 - val_loss: 0.7379 - val_accuracy: 0.8283\n",
            "Epoch 32/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 0.2186 - accuracy: 0.9233 - val_loss: 0.7678 - val_accuracy: 0.8183\n",
            "Epoch 33/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 0.2111 - accuracy: 0.9362 - val_loss: 0.7969 - val_accuracy: 0.8100\n",
            "Epoch 34/60\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.1519 - accuracy: 0.9508 - val_loss: 0.7426 - val_accuracy: 0.8217\n",
            "Epoch 35/60\n",
            "75/75 [==============================] - 6s 86ms/step - loss: 0.1420 - accuracy: 0.9542 - val_loss: 0.7906 - val_accuracy: 0.8167\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import TensorBoard\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = action_model(x_train.shape[1:], 10)\n",
        "opt = Adam(lr=0.0001, decay=1e-6)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n",
        "logdir = \"logs/NMNIST_ConvLSTM\"\n",
        "# Training  the model along with creating callbacks to tensorboard for graphical visualization of training process\n",
        "tbcallback = keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=60, validation_data=(x_val, y_val), callbacks=[early_stopping, tbcallback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/MyDrive/models/custom_conv_lstm_nmnist_recon.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "# del model  # deletes the existing model"
      ],
      "metadata": {
        "id": "gsWKrb2QUjPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results"
      ],
      "metadata": {
        "id": "26iulJ-2s1qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/models/custom_conv_lstm_nmnist_recon.h5')"
      ],
      "metadata": {
        "id": "mfun7M6NTyWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "y_pred = model.predict(x_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvwd9E62s3U7",
        "outputId": "1c4bb95e-beee-4e4d-8201-c687a4c713d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.6526700258255005\n",
            "Test accuracy: 0.8320000171661377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
      ],
      "metadata": {
        "id": "M_iyFrznZJ6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e61a7ba-f657-47bb-dd74-c95e1a7b2bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91        75\n",
            "           1       0.99      0.92      0.95        75\n",
            "           2       0.93      0.85      0.89        75\n",
            "           3       0.79      0.76      0.78        75\n",
            "           4       0.96      0.73      0.83        75\n",
            "           5       0.71      0.81      0.76        75\n",
            "           6       0.81      0.92      0.86        75\n",
            "           7       0.82      0.84      0.83        75\n",
            "           8       0.68      0.68      0.68        75\n",
            "           9       0.82      0.85      0.84        75\n",
            "\n",
            "    accuracy                           0.83       750\n",
            "   macro avg       0.84      0.83      0.83       750\n",
            "weighted avg       0.84      0.83      0.83       750\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import seaborn as sns\n",
        "\n",
        "#Create confusion matrix and normalizes it over predicted (columns)\n",
        "result = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), normalize='pred')\n",
        "\n",
        "ax = sns.heatmap(result, annot=False, cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix for NMNIST Classification with Custom ConvLSTM Network\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([i for i in range(10)])\n",
        "ax.yaxis.set_ticklabels([i for i in range(10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "G5HIoQTlLgeA",
        "outputId": "c6262716-65db-4524-9cc5-5f9bb963ce60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0.5, '0'),\n",
              " Text(0, 1.5, '1'),\n",
              " Text(0, 2.5, '2'),\n",
              " Text(0, 3.5, '3'),\n",
              " Text(0, 4.5, '4'),\n",
              " Text(0, 5.5, '5'),\n",
              " Text(0, 6.5, '6'),\n",
              " Text(0, 7.5, '7'),\n",
              " Text(0, 8.5, '8'),\n",
              " Text(0, 9.5, '9')]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DVS128 Gesture"
      ],
      "metadata": {
        "id": "AMEG1dxdKugj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "qplmRjxsVFvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### old"
      ],
      "metadata": {
        "id": "6EzWuicvugO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/rpg_e2vid/data/DVS128Gesture\n",
        "!rm -rf /content/datasets/DVS128Gesture\n",
        "!mkdir /content/datasets\n",
        "!unzip -q /content/drive/MyDrive/DVS128Gesture/'DVS  Gesture dataset.zip' -d /content/tmp\n",
        "!tar -xzf /content/tmp/'DVS  Gesture dataset'/DvsGesture.tar.gz -C /content/datasets\n",
        "!rm -rf tmp\n",
        "!pip3 install -q dv\n",
        "from dv import LegacyAedatFile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def read_aedat_events(input_file, output_file):\n",
        "  text = \"128 128\\n\"\n",
        "  with LegacyAedatFile(input_file) as f:\n",
        "    for event in f:\n",
        "      text = text + \"{0} {1} {2} {3}\\n\".format(event.timestamp, event.x, event.y, event.polarity)\n",
        "\n",
        "  # Open a file with access mode 'a'\n",
        "  file_object = open(output_file, 'w')\n",
        "  # Append 'hello' at the end of file\n",
        "  file_object.write(text)\n",
        "  # Close the file\n",
        "  file_object.close()\n",
        "\n",
        "os.mkdir(\"/content/rpg_e2vid/data/DVS128Gesture\")\n",
        "max_samples = 100\n",
        "\n",
        "def load_dvs_samples(train):\n",
        "  folder = \"train\" if train else \"test\"\n",
        "  os.mkdir(\"/content/rpg_e2vid/data/DVS128Gesture/{0}\".format(folder))\n",
        "\n",
        "  with open(\"/content/datasets/DvsGesture/trials_to_{0}.txt\".format(folder)) as file:\n",
        "      lines = file.readlines()\n",
        "      train_files = [line.rstrip() for line in lines]\n",
        "  print(\"Loading {0}ing samples:\".format(folder))\n",
        "  count = 0\n",
        "  for file_name in train_files:\n",
        "    if count < (max_samples if train else max_samples /4):\n",
        "      zip_directory = \"/content/rpg_e2vid/data/DVS128Gesture/{0}/{1}\".format(folder, file_name[:-6])\n",
        "      os.mkdir(zip_directory)\n",
        "      input_directory = \"/content/datasets/DvsGesture/{0}\".format(file_name)\n",
        "      output_directory = \"{0}/events.txt\".format(zip_directory)\n",
        "      print(\"- {0}\".format(file_name))\n",
        "      e = read_aedat_events(input_directory, output_directory)\n",
        "      shutil.make_archive(zip_directory, 'zip', zip_directory)\n",
        "      shutil.rmtree(zip_directory, ignore_errors=False, onerror=None)\n",
        "    count = count + 1\n",
        "\n",
        "load_dvs_samples(train=True)\n",
        "load_dvs_samples(train=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PQ_5QGkeVFZw",
        "outputId": "1aa9178f-50c7-48cc-ec46-7cd4f43bc488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/datasets’: File exists\n",
            "Loading training samples:\n",
            "- user01_fluorescent.aedat\n",
            "- user01_fluorescent_led.aedat\n",
            "- user01_lab.aedat\n",
            "- user01_led.aedat\n",
            "- user01_natural.aedat\n",
            "- user02_fluorescent.aedat\n",
            "- user02_fluorescent_led.aedat\n",
            "- user02_lab.aedat\n",
            "- user02_led.aedat\n",
            "- user02_natural.aedat\n",
            "- user03_fluorescent.aedat\n",
            "- user03_fluorescent_led.aedat\n",
            "- user03_led.aedat\n",
            "- user03_natural.aedat\n",
            "- user04_fluorescent.aedat\n",
            "- user04_fluorescent_led.aedat\n",
            "- user04_led.aedat\n",
            "- user04_natural.aedat\n",
            "- user05_fluorescent.aedat\n",
            "- user05_fluorescent_led.aedat\n",
            "- user05_lab.aedat\n",
            "- user05_led.aedat\n",
            "- user05_natural.aedat\n",
            "- user06_fluorescent.aedat\n",
            "- user06_fluorescent_led.aedat\n",
            "- user06_lab.aedat\n",
            "- user06_led.aedat\n",
            "- user06_natural.aedat\n",
            "- user07_fluorescent.aedat\n",
            "- user07_fluorescent_led.aedat\n",
            "- user07_lab.aedat\n",
            "- user07_led.aedat\n",
            "- user08_fluorescent.aedat\n",
            "- user08_fluorescent_led.aedat\n",
            "- user08_lab.aedat\n",
            "- user08_led.aedat\n",
            "- user09_fluorescent.aedat\n",
            "- user09_fluorescent_led.aedat\n",
            "- user09_lab.aedat\n",
            "- user09_led.aedat\n",
            "- user09_natural.aedat\n",
            "- user10_fluorescent.aedat\n",
            "- user10_fluorescent_led.aedat\n",
            "- user10_lab.aedat\n",
            "- user10_led.aedat\n",
            "- user11_fluorescent.aedat\n",
            "- user11_fluorescent_led.aedat\n",
            "- user11_natural.aedat\n",
            "- user12_fluorescent_led.aedat\n",
            "- user12_led.aedat\n",
            "- user13_fluorescent.aedat\n",
            "- user13_fluorescent_led.aedat\n",
            "- user13_lab.aedat\n",
            "- user13_led.aedat\n",
            "- user13_natural.aedat\n",
            "- user14_fluorescent.aedat\n",
            "- user14_fluorescent_led.aedat\n",
            "- user14_led.aedat\n",
            "- user14_natural.aedat\n",
            "- user15_fluorescent.aedat\n",
            "- user15_fluorescent_led.aedat\n",
            "- user15_lab.aedat\n",
            "- user15_led.aedat\n",
            "- user15_natural.aedat\n",
            "- user16_fluorescent.aedat\n",
            "- user16_lab.aedat\n",
            "- user16_led.aedat\n",
            "- user16_natural.aedat\n",
            "- user17_fluorescent.aedat\n",
            "- user17_fluorescent_led.aedat\n",
            "- user17_lab.aedat\n",
            "- user17_led.aedat\n",
            "- user17_natural.aedat\n",
            "- user18_fluorescent.aedat\n",
            "- user18_fluorescent_led.aedat\n",
            "- user18_lab.aedat\n",
            "- user18_led.aedat\n",
            "- user19_fluorescent.aedat\n",
            "- user19_fluorescent_led.aedat\n",
            "- user19_lab.aedat\n",
            "- user19_led.aedat\n",
            "- user19_natural.aedat\n",
            "- user20_fluorescent.aedat\n",
            "- user20_fluorescent_led.aedat\n",
            "- user20_led.aedat\n",
            "- user21_fluorescent.aedat\n",
            "- user21_fluorescent_led.aedat\n",
            "- user21_lab.aedat\n",
            "- user21_natural.aedat\n",
            "- user22_fluorescent.aedat\n",
            "- user22_fluorescent_led.aedat\n",
            "- user22_lab.aedat\n",
            "- user22_led.aedat\n",
            "- user22_natural.aedat\n",
            "- user23_fluorescent.aedat\n",
            "- user23_fluorescent_led.aedat\n",
            "- user23_lab.aedat\n",
            "- user23_led.aedat\n",
            "Loading testing samples:\n",
            "- user24_fluorescent.aedat\n",
            "- user24_fluorescent_led.aedat\n",
            "- user24_led.aedat\n",
            "- user25_fluorescent.aedat\n",
            "- user25_led.aedat\n",
            "- user26_fluorescent.aedat\n",
            "- user26_fluorescent_led.aedat\n",
            "- user26_lab.aedat\n",
            "- user26_led.aedat\n",
            "- user26_natural.aedat\n",
            "- user27_fluorescent.aedat\n",
            "- user27_fluorescent_led.aedat\n",
            "- user27_led.aedat\n",
            "- user27_natural.aedat\n",
            "- user28_fluorescent.aedat\n",
            "- user28_fluorescent_led.aedat\n",
            "- user28_lab.aedat\n",
            "- user28_led.aedat\n",
            "- user28_natural.aedat\n",
            "- user29_fluorescent.aedat\n",
            "- user29_fluorescent_led.aedat\n",
            "- user29_lab.aedat\n",
            "- user29_led.aedat\n",
            "- user29_natural.aedat\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-503b0c1ba7bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mload_dvs_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mload_dvs_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-503b0c1ba7bb>\u001b[0m in \u001b[0;36mload_dvs_samples\u001b[0;34m(train)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_samples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmax_samples\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mzip_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/rpg_e2vid/data/DVS128Gesture/{0}/{1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m       \u001b[0minput_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/datasets/DvsGesture/{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0moutput_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{0}/events.txt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/rpg_e2vid/data/DVS128Gesture/test/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### new"
      ],
      "metadata": {
        "id": "Jgd99HfPuo49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf datasets\n",
        "!mkdir datasets\n",
        "!mkdir datasets/DVS128Gesture\n",
        "!unzip -q /content/drive/MyDrive/DVS128Gesture/'DVS  Gesture dataset.zip' -d /content/datasets/DVS128Gesture\n",
        "!mv /content/datasets/DVS128Gesture/'DVS  Gesture dataset' /content/datasets/DVS128Gesture/download\n",
        "!pip -q install spikingjelly\n",
        "from spikingjelly.datasets.dvs128_gesture import DVS128Gesture\n",
        "\n",
        "root_dir = \"/content/datasets/DVS128Gesture\"\n",
        "train_set = DVS128Gesture(root_dir, train=True, data_type='event')\n",
        "test_set = DVS128Gesture(root_dir, train=False, data_type='event')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saCfzW9cjsj5",
        "outputId": "f63b5621-a819-4f01-f8f5-cc68f5dd9a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The [/content/datasets/DVS128Gesture/download] directory for saving downloaded files already exists, check files...\n",
            "Mkdir [/content/datasets/DVS128Gesture/extract].\n",
            "Extract [/content/datasets/DVS128Gesture/download/DvsGesture.tar.gz] to [/content/datasets/DVS128Gesture/extract].\n",
            "Mkdir [/content/datasets/DVS128Gesture/events_np].\n",
            "Start to convert the origin data from [/content/datasets/DVS128Gesture/extract] to [/content/datasets/DVS128Gesture/events_np] in np.ndarray format.\n",
            "Mkdir [('/content/datasets/DVS128Gesture/events_np/train', '/content/datasets/DVS128Gesture/events_np/test').\n",
            "Mkdir ['0', '4', '8', '7', '2', '3', '5', '1', '10', '9', '6'] in [/content/datasets/DVS128Gesture/events_np/train] and ['0', '4', '8', '7', '2', '3', '5', '1', '10', '9', '6'] in [/content/datasets/DVS128Gesture/events_np/test].\n",
            "Start the ThreadPoolExecutor with max workers = [4].\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user01_fluorescent_led.aedat] to samples.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user01_led.aedat] to samples.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user01_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user01_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user01_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user01_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user01_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user01_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user01_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user01_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user01_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user01_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user01_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user01_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user01_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user01_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user01_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user01_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user01_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user01_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user01_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user01_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user01_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user01_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user01_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user01_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user01_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user01_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user01_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user01_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user01_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user01_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user01_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user01_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user01_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user01_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user01_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user01_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user01_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user01_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user01_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user01_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user01_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user01_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user01_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user01_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user01_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user01_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user01_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user01_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user01_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user02_fluorescent.aedat] to samples.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user02_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user01_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user02_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user02_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user02_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user02_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user01_natural.aedat] to samples.[/content/datasets/DVS128Gesture/events_np/train/2/user02_fluorescent_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user02_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user01_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user02_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user02_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user01_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user02_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user02_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user02_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user01_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user02_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user02_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user02_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user02_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user02_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user02_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user02_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user02_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user02_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user01_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user02_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user02_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user02_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user02_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user02_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user02_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user01_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user02_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user02_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user02_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user01_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user02_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user01_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user02_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user02_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user02_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user01_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user02_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user02_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user02_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user02_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user02_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user02_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user01_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user02_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user02_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user02_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user01_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user02_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user02_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user02_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user01_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user02_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user02_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user02_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user02_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user01_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user02_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user02_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user02_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user02_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user02_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user02_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user02_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user02_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user02_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user02_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user02_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user03_fluorescent_led.aedat] to samples.[/content/datasets/DVS128Gesture/events_np/train/9/user02_natural_0.npz] saved.\n",
            "\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user03_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user03_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user02_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user03_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user03_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user03_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user03_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user03_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user03_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user03_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user03_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user03_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user03_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user03_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user03_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user03_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user03_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user03_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user03_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user03_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user03_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user03_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user03_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user03_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user03_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user03_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user03_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user03_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user03_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user03_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user03_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user03_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user03_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user03_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user03_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user03_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user03_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user03_led_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/9/user03_fluorescent_0.npz] saved.\n",
            "\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user04_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user04_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user04_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user03_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user04_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user03_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user03_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user04_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user04_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user04_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user04_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user04_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user03_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user03_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user04_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user04_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user04_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user04_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user03_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user04_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user04_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user03_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user04_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user04_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user03_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user04_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user03_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user04_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user03_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user04_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user04_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user03_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user03_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user04_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user04_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user04_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user04_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user04_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user03_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user04_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user04_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user04_led_0.npz] saved.Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user05_fluorescent.aedat] to samples.\n",
            "\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user04_natural.aedat] to samples.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user05_fluorescent_led.aedat] to samples.[/content/datasets/DVS128Gesture/events_np/train/0/user05_fluorescent_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user04_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user05_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user05_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user04_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user04_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user05_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user05_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user04_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user04_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user04_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user05_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user05_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user04_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user05_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user04_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user04_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user05_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user05_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user05_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user04_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user04_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user05_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user05_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user05_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user04_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user05_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user04_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user04_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user05_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user05_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user04_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user04_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user04_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user05_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user05_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user04_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user05_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user05_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user05_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user04_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user05_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user05_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user05_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user04_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user05_lab_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/10/user05_fluorescent_led_0.npz] saved.\n",
            "\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user05_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user04_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user05_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user05_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user05_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user05_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user04_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user05_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user05_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user05_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user05_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user05_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user05_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user06_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user05_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user05_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user06_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user05_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user06_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user05_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user06_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user05_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user05_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user05_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user05_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user05_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user05_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user06_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user05_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user05_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user06_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user05_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user05_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user05_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user06_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user05_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user05_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user05_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user05_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user05_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user06_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user05_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user05_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user05_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user06_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user05_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user06_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user05_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user06_lab.aedat] to samples.[/content/datasets/DVS128Gesture/events_np/train/7/user06_fluorescent_1.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user06_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user06_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user06_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user06_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user06_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user06_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user06_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user06_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user06_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user06_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user06_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user06_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user06_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user06_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user06_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user06_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user06_lab_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/3/user06_led_0.npz] saved.\n",
            "\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user06_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user06_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user06_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user06_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user06_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user06_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user06_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user06_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user06_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user06_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user06_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user06_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user06_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user06_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user06_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user06_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user06_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user06_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user06_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user06_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user06_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user06_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user06_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user06_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user06_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user06_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user06_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user06_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user07_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user06_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user06_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user07_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user07_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user07_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user07_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user06_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user06_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user07_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user07_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user06_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user07_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user07_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user06_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user07_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user07_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user06_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user07_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user07_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user07_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user07_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user07_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user07_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user07_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user07_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user07_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user07_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user07_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user07_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user07_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user07_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user07_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user07_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user07_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user07_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user07_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user07_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user07_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user07_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user07_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user07_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user08_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user08_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user07_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user07_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user08_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user07_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user07_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user07_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user08_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user07_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user08_fluorescent_led.aedat] to samples.[/content/datasets/DVS128Gesture/events_np/train/7/user07_led_1.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user08_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user08_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user07_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user07_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user08_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user08_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user07_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user07_lab_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/2/user08_fluorescent_led_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user08_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user07_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user08_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user08_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user08_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user08_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user08_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user07_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user08_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user08_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user08_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user08_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user08_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user08_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user07_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user08_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user08_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user08_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user08_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user08_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user08_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user07_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user08_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user08_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user08_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user07_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user08_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user08_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user08_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user08_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user08_lab_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/10/user07_lab_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user08_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user08_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user09_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user08_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user09_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user09_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user08_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user08_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user09_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user09_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user09_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user08_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user09_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user09_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user08_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user08_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user08_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user09_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user09_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user08_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user08_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user09_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user08_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user09_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user08_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user09_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user08_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user09_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user09_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user08_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user08_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user09_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user09_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user09_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user09_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user09_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user09_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user09_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user09_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user09_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user09_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user09_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user09_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user09_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user09_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user09_lab_0.npz] saved.Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user09_led.aedat] to samples.\n",
            "\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user09_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user09_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user09_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user09_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user09_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user09_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user09_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user10_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user09_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user10_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user10_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user09_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user09_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user10_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user09_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user09_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user09_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user10_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user09_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user10_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user09_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user09_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user09_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user09_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user10_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user09_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user09_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user10_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user09_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user09_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user09_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user09_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user10_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user09_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user09_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user10_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user09_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user09_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user10_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user09_natural_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/7/user09_led_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user09_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user10_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user09_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user10_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user09_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user10_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user10_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user09_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user10_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user10_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user10_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user10_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user10_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user10_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user10_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user10_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user10_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user10_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user10_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user10_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user10_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user10_fluorescent_led_1.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/3/user10_led_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user10_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user10_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user10_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user10_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user10_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user10_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user10_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user10_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user10_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user10_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user10_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user10_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user10_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user11_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user11_fluorescent_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/8/user10_led_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user10_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user10_led_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/1/user11_fluorescent_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user10_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user10_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user11_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user10_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user11_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user10_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user10_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user11_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user10_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user11_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user11_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user11_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user12_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user12_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user11_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user12_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user11_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user12_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user11_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user11_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user12_fluorescent_led_0.npz] saved.Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user11_natural.aedat] to samples.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user11_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user11_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user12_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user12_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user11_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user11_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user12_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user11_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user11_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user12_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user11_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user12_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user11_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user12_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user11_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user11_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user12_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user12_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user12_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user12_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user12_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user12_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user11_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user12_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user11_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user11_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user12_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user11_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user12_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user11_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user13_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user11_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user13_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user12_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user13_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user11_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user12_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user11_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user13_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user11_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user12_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user11_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user12_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user13_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user11_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user12_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user12_led_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/10/user11_natural_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user12_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user11_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user13_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user11_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user13_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user13_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user11_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user13_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user13_fluorescent_1.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user13_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user13_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user13_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user13_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user13_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user13_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user13_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user13_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user13_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user13_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user13_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user13_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user13_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user13_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user13_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user13_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user13_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user13_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user13_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user13_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user13_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user13_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user13_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user13_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user13_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user13_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user13_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user13_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user13_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user13_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user13_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user13_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user13_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user13_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user13_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user13_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user13_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user13_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user13_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user13_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user13_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user13_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user13_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user13_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user13_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user13_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user13_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user13_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user13_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user13_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user13_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user13_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user14_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user13_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user13_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user14_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user14_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user13_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user14_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user14_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user14_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user14_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user14_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user14_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user14_fluorescent_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/2/user14_fluorescent_led_0.npz] saved.\n",
            "\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user14_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user14_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user14_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user14_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user14_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user14_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user14_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user14_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user14_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user14_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user14_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user14_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user14_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user14_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user14_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user14_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user14_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user14_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user14_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user14_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user14_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user14_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user14_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user14_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user14_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user14_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user14_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user14_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user14_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user14_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user14_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user15_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user15_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user14_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user14_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user14_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user15_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user14_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user14_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user15_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user14_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user14_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user15_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user14_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user14_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user15_fluorescent_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/0/user15_fluorescent_led_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user14_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user15_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user15_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user15_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user15_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user15_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user15_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user15_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user15_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user15_led_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/7/user15_fluorescent_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user15_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user15_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user15_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user15_fluorescent_1.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user15_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user15_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user15_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user15_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user15_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user15_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user15_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user15_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user15_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user15_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user15_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user15_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user15_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user15_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user15_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user15_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user15_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user15_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user15_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user15_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user15_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user15_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user15_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user15_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user15_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user15_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user15_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user15_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user15_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user16_fluorescent.aedat] to samples.[/content/datasets/DVS128Gesture/events_np/train/2/user15_natural_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user16_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user15_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user15_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user15_natural_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/1/user16_fluorescent_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user15_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user16_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user15_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user15_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user15_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user15_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user16_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user15_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user15_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user16_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user15_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user16_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user15_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user15_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user16_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user16_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user15_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user16_fluorescent_1.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user16_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user16_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user16_fluorescent_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/0/user16_led_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user16_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user16_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user16_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user16_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user16_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user16_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user16_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user16_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user16_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user16_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user17_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user16_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user17_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user16_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user16_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user17_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user16_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user16_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user16_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user17_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user16_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user16_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user16_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user17_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user16_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user16_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user17_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user16_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user16_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user17_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user16_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user17_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user16_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user17_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user16_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user16_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user17_fluorescent_1.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user17_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user17_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user16_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user17_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user17_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user16_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user17_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user17_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user16_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user17_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user16_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user16_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user17_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user16_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user16_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user16_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user17_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user16_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user17_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user16_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user17_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user16_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user17_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user17_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user17_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user17_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user17_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user17_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user17_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user17_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user18_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user17_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user18_fluorescent_0.npz] saved.Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user17_natural.aedat] to samples.\n",
            "\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user17_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user18_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user18_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user17_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user17_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user18_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user17_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user18_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user17_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user18_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user17_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user18_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user17_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user18_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user18_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user18_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user17_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user18_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user17_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user18_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user17_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user17_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user17_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user18_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user17_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user17_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user18_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user17_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user18_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user18_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user18_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user18_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user17_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user18_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user17_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user17_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user18_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user18_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user18_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user18_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user18_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user17_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user17_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user18_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user17_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user17_natural_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/7/user17_led_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user17_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user17_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user17_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user17_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user17_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user17_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user18_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user18_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user17_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user17_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user18_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user18_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user17_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user18_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user18_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user18_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user18_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user17_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user18_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user18_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user18_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user17_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user18_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user18_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user18_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user18_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user18_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user18_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user18_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user18_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user18_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user19_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user18_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user18_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user19_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user18_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user18_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user19_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user19_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user19_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user18_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user19_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user18_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user19_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user19_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user19_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user19_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user19_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user19_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user19_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user19_lab_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/train/3/user19_fluorescent_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user19_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user19_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user19_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user19_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user19_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user19_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user19_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user19_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user19_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user19_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user19_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user19_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user19_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user19_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user19_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user19_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user19_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user19_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user19_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user19_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user19_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user19_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user19_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user19_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user19_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user19_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user19_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user19_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user19_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user19_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user19_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user19_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user19_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user19_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user19_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user19_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user19_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user19_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user19_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user19_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user19_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user20_fluorescent.aedat] to samples.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user20_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user19_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user20_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user20_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user20_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user20_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user20_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user20_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user20_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user20_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user20_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user20_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user20_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user19_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user20_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user20_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user20_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user20_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user20_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user20_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user20_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user20_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user19_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user20_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user20_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user20_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user20_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user20_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user20_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user20_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user20_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user20_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user20_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user19_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user20_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user20_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user20_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user20_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user20_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user20_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user19_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user20_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user20_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user19_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user19_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user21_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user19_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user21_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user21_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user21_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user19_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user21_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user21_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user21_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user21_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user21_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user21_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user21_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user21_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user21_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user21_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user21_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user21_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user21_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user21_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user21_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user21_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user21_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user21_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user21_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user21_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user21_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user21_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user21_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user21_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user21_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user21_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user21_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user21_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user21_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user21_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user21_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user21_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user21_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user21_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user21_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user21_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user21_natural_1.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user22_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user22_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user21_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user21_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user22_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user22_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user21_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user21_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user21_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user21_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user22_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user22_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user21_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user21_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user22_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user21_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user22_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user21_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user21_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user22_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user22_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user22_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user22_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user22_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user22_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user22_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user22_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user22_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user22_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user22_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user22_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user22_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user22_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user22_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user22_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user22_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user22_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user22_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user22_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user22_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user22_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user22_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user22_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user22_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user22_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user22_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user22_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user22_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user22_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user22_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user22_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user22_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user22_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user22_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user22_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user22_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user22_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user22_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user22_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user22_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user22_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user22_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user22_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user23_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user22_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user22_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user22_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user23_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user23_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user22_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user22_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user23_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user23_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user23_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user23_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user22_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user23_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user22_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user22_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user22_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user23_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user23_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user22_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user22_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user23_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user23_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user22_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user23_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user22_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user23_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user23_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user23_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user23_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user23_led.aedat] to samples.Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user23_lab.aedat] to samples.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user23_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user23_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user23_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/0/user23_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user23_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user23_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/1/user23_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user23_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user23_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/2/user23_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user23_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user23_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user23_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user23_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user23_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/3/user23_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user23_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user23_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user23_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/4/user23_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user23_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/5/user23_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user23_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/6/user23_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user23_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user23_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user23_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user23_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/7/user23_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user23_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/8/user23_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/9/user23_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/train/10/user23_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user24_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user24_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user24_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user24_fluorescent.aedat] to samples.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user24_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user24_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user25_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user24_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user24_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user24_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user25_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user24_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user25_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user24_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user24_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user25_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user24_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user25_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user24_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user24_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user25_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user24_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user25_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user24_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user25_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user24_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user24_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user25_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user24_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user25_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user24_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user24_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user24_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user24_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user24_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user24_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user25_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user24_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user24_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user24_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user25_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user24_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user24_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user24_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user24_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user25_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user24_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user24_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user24_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user24_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user26_fluorescent.aedat] to samples.[/content/datasets/DVS128Gesture/events_np/test/9/user24_fluorescent_0.npz] saved.\n",
            "\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user26_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user26_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user26_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user25_led.aedat] to samples.[/content/datasets/DVS128Gesture/events_np/test/10/user24_fluorescent_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user26_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user26_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user25_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user26_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user26_fluorescent_led_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/test/1/user25_led_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user26_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user25_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user26_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user26_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user25_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user26_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user26_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user25_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user26_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user26_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user25_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user26_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user26_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user25_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user26_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user26_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user25_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user26_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user26_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user26_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user26_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user25_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user26_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user26_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user25_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user26_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user26_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user26_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user25_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user26_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user26_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user26_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user25_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user26_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user26_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user26_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user26_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user26_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user26_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user26_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user27_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user26_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user27_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user26_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user27_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user27_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user26_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user26_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user26_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user26_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user26_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user27_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user26_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user26_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user26_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user26_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user26_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user27_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user26_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user26_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user26_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user27_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user26_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user26_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user26_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user27_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user26_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user26_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user26_natural_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/test/7/user27_fluorescent_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user26_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user27_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user26_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user27_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user27_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user27_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user26_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user26_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user27_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user27_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user27_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user26_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user27_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user27_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user27_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user26_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user27_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user27_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user27_fluorescent_led_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/test/1/user27_led_0.npz] saved.\n",
            "\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user27_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user27_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user27_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user27_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user27_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user27_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user27_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user28_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user27_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user28_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user27_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user27_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user28_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user27_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user27_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user28_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user27_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user27_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user27_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user27_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user27_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user28_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user27_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user27_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user28_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user27_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user27_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user28_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user27_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user28_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user27_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user28_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user27_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user28_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user27_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user28_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user27_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user28_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user27_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user28_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user28_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user27_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user28_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user28_fluorescent_led_0.npz] saved.[/content/datasets/DVS128Gesture/events_np/test/10/user27_natural_0.npz] saved.\n",
            "\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user28_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user28_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user28_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user28_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user28_fluorescent_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user28_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user28_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user28_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user28_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user28_led_0.npz] saved.Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user28_natural.aedat] to samples.\n",
            "\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user28_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user28_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user28_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user28_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user28_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user28_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user28_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user28_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user28_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user28_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user28_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user28_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user28_natural_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user29_fluorescent.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user28_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user28_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user28_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user29_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user29_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user28_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user29_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user28_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user28_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user28_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user28_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user29_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user28_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user28_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user28_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user28_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user29_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user28_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user28_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user28_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user29_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user28_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user28_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user29_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user28_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user29_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user28_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user28_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user29_fluorescent_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user28_lab_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user29_fluorescent_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user29_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user29_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user28_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user29_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user29_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user29_fluorescent_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user28_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user29_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user28_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user29_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user28_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user29_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user29_led.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user29_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user29_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user29_natural.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user29_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user29_fluorescent_led_0.npz] saved.\n",
            "Start to split [/content/datasets/DVS128Gesture/extract/DvsGesture/user29_lab.aedat] to samples.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user29_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user29_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/0/user29_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user29_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user29_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user29_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/1/user29_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user29_fluorescent_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user29_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/2/user29_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user29_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user29_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user29_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user29_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user29_fluorescent_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user29_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user29_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user29_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/3/user29_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user29_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user29_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user29_led_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user29_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user29_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user29_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/4/user29_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user29_led_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user29_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user29_natural_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user29_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/5/user29_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user29_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user29_natural_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/6/user29_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user29_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/7/user29_lab_1.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/8/user29_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/9/user29_lab_0.npz] saved.\n",
            "[/content/datasets/DVS128Gesture/events_np/test/10/user29_lab_0.npz] saved.\n",
            "Used time = [1352.78s].\n",
            "All aedat files have been split to samples and saved into [('/content/datasets/DVS128Gesture/events_np/train', '/content/datasets/DVS128Gesture/events_np/test')].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def restructure_spikingjelly_events(input_file, output_file):\n",
        "  d = np.load(input_file)\n",
        "  d = np.array([d[\"t\"], d[\"x\"], d[\"y\"], d[\"p\"]])\n",
        "  p = [[128, 128]]\n",
        "  for i in range(len(d[0])):\n",
        "    p.append(d[:, i])\n",
        "  text = \"\"\n",
        "  for item in p:\n",
        "    if(len(item) == 4):\n",
        "      text = text + \"{0} {1} {2} {3}\\n\".format(item[0], item[1], item[2], item[3])\n",
        "    else:\n",
        "      text = text + \"{0} {1}\\n\".format(item[0], item[1])\n",
        "  # Open a file with access mode 'a'\n",
        "  outfile = open(output_file, 'w')\n",
        "  # Append 'hello' at the end of file\n",
        "  outfile.write(text)\n",
        "  # Close the file\n",
        "  outfile.close()"
      ],
      "metadata": {
        "id": "jF_dFdU91nEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "os.mkdir(\"/content/rpg_e2vid/data/DVS128Gesture\")\n",
        "max_samples = 300\n",
        "\n",
        "def load_dvs_gesture_samples(train):\n",
        "  print(\"Loading {0} samples\".format(\"training\" if train else \"testing\"))\n",
        "  folder = \"train\" if train else \"test\"\n",
        "  os.mkdir(\"/content/rpg_e2vid/data/DVS128Gesture/{0}\".format(folder))\n",
        "  for act_class in range(11):\n",
        "    print(' class {0}'.format(act_class))\n",
        "    directory = \"/content/datasets/DVS128Gesture/events_np/{0}/{1}/\".format(folder, act_class)\n",
        "    os.mkdir(\"/content/rpg_e2vid/data/DVS128Gesture/{0}/{1}\".format(folder, act_class))\n",
        "    count = 0\n",
        "    for sample in os.listdir(directory):\n",
        "        zip_directory = \"/content/rpg_e2vid/data/DVS128Gesture/{0}/{1}/{2}\".format(folder, act_class, sample[:-4])\n",
        "        input_directory = os.path.join(directory, sample)\n",
        "        output_directory = \"{0}/events.txt\".format(zip_directory)\n",
        "        if os.path.isfile(input_directory) and count < (max_samples if train else max_samples /4):\n",
        "            if(count % 60 != 0 or count == 0):\n",
        "              print(\".\", end=\"\")\n",
        "            else:\n",
        "              print(\".\")\n",
        "            os.mkdir(zip_directory)\n",
        "            # events = read_events(input_directory, output_directory)\n",
        "            restructure_spikingjelly_events(input_directory, output_directory)\n",
        "            shutil.make_archive(zip_directory, 'zip', zip_directory)\n",
        "            shutil.rmtree(zip_directory, ignore_errors=False, onerror=None)\n",
        "        count = count + 1\n",
        "    print(\"\")\n",
        "\n",
        "load_dvs_gesture_samples(train=True)\n",
        "load_dvs_gesture_samples(train=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twXRr4JJ0EKs",
        "outputId": "9f74a767-82b6-4f0e-ec4f-2b471abd6aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training samples\n",
            " class 0\n",
            ".............................................................\n",
            "....................................\n",
            " class 1\n",
            ".............................................................\n",
            ".....................................\n",
            " class 2\n",
            ".............................................................\n",
            ".....................................\n",
            " class 3\n",
            ".............................................................\n",
            ".....................................\n",
            " class 4\n",
            ".............................................................\n",
            ".....................................\n",
            " class 5\n",
            ".............................................................\n",
            ".....................................\n",
            " class 6\n",
            ".............................................................\n",
            "......................................\n",
            " class 7\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...............\n",
            " class 8\n",
            ".............................................................\n",
            ".....................................\n",
            " class 9\n",
            ".............................................................\n",
            ".....................................\n",
            " class 10\n",
            ".............................................................\n",
            ".....................................\n",
            "Loading testing samples\n",
            " class 0\n",
            "........................\n",
            " class 1\n",
            "........................\n",
            " class 2\n",
            "........................\n",
            " class 3\n",
            "........................\n",
            " class 4\n",
            "........................\n",
            " class 5\n",
            "........................\n",
            " class 6\n",
            "........................\n",
            " class 7\n",
            "................................................\n",
            " class 8\n",
            "........................\n",
            " class 9\n",
            "........................\n",
            " class 10\n",
            "........................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and save Video Reconstructions"
      ],
      "metadata": {
        "id": "9rY4HiYSf6SQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### old"
      ],
      "metadata": {
        "id": "wHE0rf_HFo7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "!rm -rf /content/reconstructions\n",
        "os.mkdir(\"/content/reconstructions\")\n",
        "os.mkdir(\"/content/reconstructions/DVS128Gesture\")\n",
        "\n",
        "def reconstruct_DVS128(train):\n",
        "  print(\"Reconstructing {0} samples\".format(\"training\" if train else \"testing\"))\n",
        "  folder = \"train\" if train else \"test\"\n",
        "  recon_directory = \"/content/reconstructions/DVS128Gesture/{0}\".format(folder)\n",
        "  sample_directory = \"/content/rpg_e2vid/data/DVS128Gesture/{0}\".format(folder)\n",
        "  os.mkdir(recon_directory)\n",
        "  for sample in os.listdir(sample_directory):\n",
        "    new_directory = \"{0}/{1}\".format(recon_directory, sample[:-4])\n",
        "    os.mkdir(new_directory)\n",
        "    print(\"- {0}\".format(sample[:-4]))\n",
        "    cmd = \"python /content/rpg_e2vid/run_reconstruction.py \\\n",
        "          -c /content/rpg_e2vid/pretrained/E2VID_lightweight.pth.tar \\\n",
        "          -i {0}/{1} \\\n",
        "          --auto_hdr \\\n",
        "          --output_folder {2}/{1}\".format(sample_directory, sample, recon_directory)\n",
        "    # subprocess.call(cmd, shell=True)\n",
        "    process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
        "    output, error = process.communicate()\n",
        "    # print(output.decode(\"utf-8\") )\n",
        "  print(\"\")\n",
        "\n",
        "reconstruct_DVS128(train=True)\n",
        "reconstruct_DVS128(train=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riPK-EvCf979",
        "outputId": "f4bf3985-c223-4432-dc05-16c3c25e76ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructing training samples\n",
            "- user01_fluorescent\n",
            "- user12_fluorescent_led\n",
            "- user16_led\n",
            "- user13_led\n",
            "- user23_led\n",
            "- user19_fluorescent\n",
            "- user06_fluorescent_led\n",
            "- user08_fluorescent\n",
            "- user04_fluorescent_led\n",
            "- user02_led\n",
            "- user14_fluorescent\n",
            "- user04_fluorescent\n",
            "- user05_fluorescent_led\n",
            "- user14_fluorescent_led\n",
            "- user03_led\n",
            "- user05_fluorescent\n",
            "- user22_led\n",
            "- user15_led\n",
            "- user23_fluorescent_led\n",
            "- user11_natural\n",
            "- user15_fluorescent\n",
            "- user08_led\n",
            "- user21_fluorescent\n",
            "- user17_fluorescent\n",
            "- user22_lab\n",
            "- user21_lab\n",
            "- user18_lab\n",
            "- user03_fluorescent\n",
            "- user05_natural\n",
            "- user23_lab\n",
            "- user16_natural\n",
            "- user09_lab\n",
            "- user06_natural\n",
            "- user02_natural\n",
            "- user13_fluorescent\n",
            "- user15_lab\n",
            "- user17_natural\n",
            "- user05_led\n",
            "- user16_lab\n",
            "- user20_fluorescent_led\n",
            "- user11_fluorescent\n",
            "- user16_fluorescent\n",
            "- user17_led\n",
            "- user22_fluorescent_led\n",
            "- user13_natural\n",
            "- user10_fluorescent_led\n",
            "- user05_lab\n",
            "- user17_lab\n",
            "- user14_natural\n",
            "- user04_led\n",
            "- user01_led\n",
            "- user07_fluorescent\n",
            "- user13_fluorescent_led\n",
            "- user21_natural\n",
            "- user09_fluorescent_led\n",
            "- user02_fluorescent\n",
            "- user09_natural\n",
            "- user22_fluorescent\n",
            "- user10_lab\n",
            "- user14_led\n",
            "- user20_fluorescent\n",
            "- user09_led\n",
            "- user18_fluorescent_led\n",
            "- user19_lab\n",
            "- user20_led\n",
            "- user11_fluorescent_led\n",
            "- user02_lab\n",
            "- user18_fluorescent\n",
            "- user17_fluorescent_led\n",
            "- user09_fluorescent\n",
            "- user03_fluorescent_led\n",
            "- user01_fluorescent_led\n",
            "- user07_fluorescent_led\n",
            "- user19_natural\n",
            "- user08_fluorescent_led\n",
            "- user01_lab\n",
            "- user02_fluorescent_led\n",
            "- user22_natural\n",
            "- user06_lab\n",
            "- user21_fluorescent_led\n",
            "- user07_lab\n",
            "- user07_led\n",
            "- user10_fluorescent\n",
            "- user23_fluorescent\n",
            "- user18_led\n",
            "- user08_lab\n",
            "- user06_led\n",
            "- user12_led\n",
            "- user15_natural\n",
            "- user13_lab\n",
            "- user01_natural\n",
            "- user10_led\n",
            "- user04_natural\n",
            "- user06_fluorescent\n",
            "- user15_fluorescent_led\n",
            "- user03_natural\n",
            "- user19_led\n",
            "- user19_fluorescent_led\n",
            "\n",
            "Reconstructing testing samples\n",
            "- user25_fluorescent\n",
            "- user29_fluorescent\n",
            "- user28_natural\n",
            "- user29_led\n",
            "- user28_fluorescent\n",
            "- user28_led\n",
            "- user29_fluorescent_led\n",
            "- user26_led\n",
            "- user27_led\n",
            "- user29_lab\n",
            "- user25_led\n",
            "- user26_lab\n",
            "- user24_led\n",
            "- user24_fluorescent_led\n",
            "- user24_fluorescent\n",
            "- user29_natural\n",
            "- user28_fluorescent_led\n",
            "- user27_natural\n",
            "- user26_natural\n",
            "- user27_fluorescent_led\n",
            "- user26_fluorescent\n",
            "- user26_fluorescent_led\n",
            "- user28_lab\n",
            "- user27_fluorescent\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### new"
      ],
      "metadata": {
        "id": "asr_LN6hFsI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "!rm -rf /content/reconstructions\n",
        "os.mkdir(\"/content/reconstructions\")\n",
        "os.mkdir(\"/content/reconstructions/DVS128\")\n",
        "\n",
        "def reconstruct_DVS128Gesture(train):\n",
        "  print(\"Reconstructing {0} samples\".format(\"training\" if train else \"testing\"))\n",
        "  folder = \"train\" if train else \"test\"\n",
        "  os.mkdir(\"/content/reconstructions/DVS128/{0}\".format(folder))\n",
        "  for act_class in range(11):\n",
        "    print(' class {0}'.format(act_class))\n",
        "    recon_directory = \"/content/reconstructions/DVS128/{0}/{1}/\".format(folder, act_class)\n",
        "    os.mkdir(recon_directory)\n",
        "    sample_directory = \"data/DVS128Gesture/{0}/{1}/\".format(folder, act_class)\n",
        "    count = 0\n",
        "    for sample in os.listdir(\"/content/rpg_e2vid/{0}\".format(sample_directory)):\n",
        "      new_directory = \"{0}/{1}\".format(recon_directory, sample[:-4])\n",
        "      os.mkdir(new_directory)\n",
        "      if(count % 60 != 0 or count == 0):\n",
        "        print(\".\", end=\"\")\n",
        "      else:\n",
        "        print(\".\")\n",
        "      cmd = \"python /content/rpg_e2vid/run_reconstruction.py \\\n",
        "            -c /content/rpg_e2vid/pretrained/E2VID_lightweight.pth.tar \\\n",
        "            -i /content/rpg_e2vid/{0}/{1} \\\n",
        "            --auto_hdr \\\n",
        "            --output_folder {2}\".format(sample_directory, sample, new_directory)\n",
        "      # subprocess.call(cmd, shell=True)\n",
        "      process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
        "      output, error = process.communicate()\n",
        "      # print(output.decode(\"utf-8\") )\n",
        "      count = count + 1\n",
        "    print(\"\")\n",
        "\n",
        "reconstruct_DVS128Gesture(train=True)\n",
        "reconstruct_DVS128Gesture(train=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fu4Y1x_Fr0h",
        "outputId": "f544d9c0-9672-409f-b0fb-7f2d24837894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructing training samples\n",
            " class 0\n",
            ".............................................................\n",
            "....................................\n",
            " class 1\n",
            ".............................................................\n",
            ".....................................\n",
            " class 2\n",
            ".............................................................\n",
            ".....................................\n",
            " class 3\n",
            ".............................................................\n",
            ".....................................\n",
            " class 4\n",
            ".............................................................\n",
            ".....................................\n",
            " class 5\n",
            ".............................................................\n",
            ".....................................\n",
            " class 6\n",
            ".............................................................\n",
            "......................................\n",
            " class 7\n",
            ".............................................................\n",
            "............................................................\n",
            "............................................................\n",
            "...............\n",
            " class 8\n",
            ".............................................................\n",
            ".....................................\n",
            " class 9\n",
            ".............................................................\n",
            ".....................................\n",
            " class 10\n",
            ".............................................................\n",
            ".....................................\n",
            "Reconstructing testing samples\n",
            " class 0\n",
            "........................\n",
            " class 1\n",
            "........................\n",
            " class 2\n",
            ".......................\n",
            " class 3\n",
            "........................\n",
            " class 4\n",
            "........................\n",
            " class 5\n",
            "........................\n",
            " class 6\n",
            "........................\n",
            " class 7\n",
            "................................................\n",
            " class 8\n",
            "........................\n",
            " class 9\n",
            "........................\n",
            " class 10\n",
            "........................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive(\"DVS128_reconstructed\", 'zip', \"/content/reconstructions\")\n",
        "!cp /content/DVS128_reconstructed.zip /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCyqcERNNk9X",
        "outputId": "263eec3d-057a-4567-fda0-1fa0c9393c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/DVS128_reconstructed.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Video Reconstructions"
      ],
      "metadata": {
        "id": "OslND9u2SBm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/DVS128_reconstructed.zip /content\n",
        "!unzip -q /content/DVS128_reconstructed.zip -d /content/reconstructions"
      ],
      "metadata": {
        "id": "vAk13jmfLtwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### old"
      ],
      "metadata": {
        "id": "X-nuKnS1lGhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "split = 6\n",
        "max_frame_count = 0\n",
        "\n",
        "print(\"Checking training reconstructions\")\n",
        "for act_class in range(10):\n",
        "    class_directory = \"/content/reconstructions/DVS128/train/{0}\".format(act_class)\n",
        "    count = 0\n",
        "    for reconstruction in os.listdir(class_directory):\n",
        "      if count < 5 * split:\n",
        "        current_recon_dir = os.path.join(class_directory, reconstruction)\n",
        "        frame_count = 0\n",
        "        for frame in os.listdir(\"{0}/reconstruction\".format(current_recon_dir)):\n",
        "          f = os.path.join(\"{0}/reconstruction\".format(current_recon_dir), frame)\n",
        "          if frame.endswith('.png'):\n",
        "            frame_count += 1\n",
        "        if(frame_count > max_frame_count):\n",
        "          max_frame_count = frame_count\n",
        "        count += 1\n",
        "\n",
        "print(\"Checking testing reconstructions\")\n",
        "for act_class in range(10):\n",
        "    class_directory = \"/content/reconstructions/DVS128/test/{0}\".format(act_class)\n",
        "    count = 0\n",
        "    for reconstruction in os.listdir(class_directory):\n",
        "      if count < split:\n",
        "        current_recon_dir = os.path.join(class_directory, reconstruction)\n",
        "        frame_count = 0\n",
        "        for frame in os.listdir(\"{0}/reconstruction\".format(current_recon_dir)):\n",
        "          f = os.path.join(\"{0}/reconstruction\".format(current_recon_dir), frame)\n",
        "          if frame.endswith('.png'):\n",
        "            frame_count += 1\n",
        "        if(frame_count > max_frame_count):\n",
        "          max_frame_count = frame_count\n",
        "        count += 1\n",
        "\n",
        "print(\"The maximum video length in the dataset is {0} frames\".format(max_frame_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyyKYK1mMxi2",
        "outputId": "92742fdf-a03b-42d0-b0df-0c909e2868c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking training reconstructions\n",
            "Checking testing reconstructions\n",
            "The maximum video length in the dataset is 237 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import imageio\n",
        "from keras.utils import np_utils\n",
        "from itertools import islice, cycle\n",
        "\n",
        "split = 6\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "print(\"Loading training reconstructions\")\n",
        "for act_class in range(10):\n",
        "    print(' class {0}'.format(act_class))\n",
        "    class_directory = \"/content/reconstructions/DVS128/train/{0}\".format(act_class)\n",
        "    count = 0\n",
        "    for reconstruction in os.listdir(class_directory):\n",
        "      if count < split * 5:\n",
        "        current_recon_dir = os.path.join(class_directory, reconstruction)\n",
        "        if(count % 60 != 0 or count == 0):\n",
        "          print(\".\", end=\"\")\n",
        "        else:\n",
        "          print(\".\")\n",
        "        current_recon = []\n",
        "        for frame in os.listdir(\"{0}/reconstruction\".format(current_recon_dir)):\n",
        "          f = os.path.join(\"{0}/reconstruction\".format(current_recon_dir), frame)\n",
        "          if frame.endswith('.png'):\n",
        "            im = imageio.imread(f)\n",
        "            current_recon.append(im)\n",
        "        current_recon = list(islice(cycle(current_recon), max_frame_count))\n",
        "        x_train.append(current_recon)\n",
        "        y_train.append(np_utils.to_categorical(act_class, 11))\n",
        "        count = count + 1\n",
        "    print(\"\")\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "print(\"Loading testing reconstructions\")\n",
        "for act_class in range(10):\n",
        "    print(' class {0}'.format(act_class))\n",
        "    class_directory = \"/content/reconstructions/DVS128/test/{0}\".format(act_class)\n",
        "    count = 0\n",
        "    for reconstruction in os.listdir(class_directory):\n",
        "      if count < split:\n",
        "        current_recon_dir = os.path.join(class_directory, reconstruction)\n",
        "        if(count % 60 != 0 or count == 0):\n",
        "          print(\".\", end=\"\")\n",
        "        else:\n",
        "          print(\".\")\n",
        "        current_recon = []\n",
        "        for frame in os.listdir(\"{0}/reconstruction\".format(current_recon_dir)):\n",
        "          f = os.path.join(\"{0}/reconstruction\".format(current_recon_dir), frame)\n",
        "          if frame.endswith('.png'):\n",
        "            im = imageio.imread(f)\n",
        "            current_recon.append(im)\n",
        "        current_recon = list(islice(cycle(current_recon), max_frame_count))\n",
        "        x_test.append(current_recon)\n",
        "        y_test.append(np_utils.to_categorical(act_class, 11))\n",
        "        count = count + 1\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "5YKrguYlSEdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03cd5576-b23a-4a5e-f667-ea2f26bce11f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training reconstructions\n",
            " class 0\n",
            "..............................\n",
            " class 1\n",
            "..............................\n",
            " class 2\n",
            "..............................\n",
            " class 3\n",
            "..............................\n",
            " class 4\n",
            "..............................\n",
            " class 5\n",
            "..............................\n",
            " class 6\n",
            "..............................\n",
            " class 7\n",
            "..............................\n",
            " class 8\n",
            "..............................\n",
            " class 9\n",
            "..............................\n",
            "Loading testing reconstructions\n",
            " class 0\n",
            "......\n",
            " class 1\n",
            "......\n",
            " class 2\n",
            "......\n",
            " class 3\n",
            "......\n",
            " class 4\n",
            "......\n",
            " class 5\n",
            "......\n",
            " class 6\n",
            "......\n",
            " class 7\n",
            "......\n",
            " class 8\n",
            "......\n",
            " class 9\n",
            "......\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], x_train.shape[3], 1)\n",
        "x_test = np.array(x_test)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3], 1)\n",
        "\n",
        "train_mean = np.mean(x_train)\n",
        "train_max = np.max(x_train)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=4)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "# open_file = open(\"/content/DVS_recon_y_train.pkl\", \"wb\")\n",
        "# pickle.dump(y_train, open_file, protocol=4)\n",
        "# open_file.close()\n",
        "# del y_train\n",
        "\n",
        "y_val = np.array(y_val)\n",
        "# open_file = open(\"/content/DVS_recon_y_val.pkl\", \"wb\")\n",
        "# pickle.dump(y_val, open_file, protocol=4)\n",
        "# open_file.close()\n",
        "# del y_val\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "# open_file = open(\"/content/DVS_recon_y_test.pkl\", \"wb\")\n",
        "# pickle.dump(y_test, open_file, protocol=4)\n",
        "# open_file.close()\n",
        "# del y_test\n",
        "\n",
        "x_train = x_train.astype('float16')\n",
        "x_train -= train_mean\n",
        "x_train /= train_max\n",
        "\n",
        "# open_file = open(\"/content/DVS_recon_x_train.pkl\", \"wb\")\n",
        "# pickle.dump(x_train, open_file, protocol=4)\n",
        "# open_file.close()\n",
        "# del x_train\n",
        "\n",
        "x_val = x_val.astype('float16')\n",
        "x_val -= train_mean\n",
        "x_val /= train_max\n",
        "\n",
        "# open_file = open(\"/content/DVS_recon_x_val.pkl\", \"wb\")\n",
        "# pickle.dump(x_val, open_file, protocol=4)\n",
        "# open_file.close()\n",
        "# del x_val\n",
        "\n",
        "x_test = x_test.astype('float16')\n",
        "x_test -= train_mean\n",
        "x_test /= train_max\n",
        "\n",
        "# open_file = open(\"/content/DVS_recon_x_test.pkl\", \"wb\")\n",
        "# pickle.dump(x_test, open_file, protocol=4)\n",
        "# open_file.close()\n",
        "# del x_test"
      ],
      "metadata": {
        "id": "dpITZtxj-Dgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grJgFtA6racp",
        "outputId": "5a07c885-3d32-4bb9-c427-6bfca36c15c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(240, 237, 128, 128, 1)\n",
            "(240, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "disp = x_train[0][0]\n",
        "disp = disp.reshape(disp.shape[:-1])\n",
        "disp = (disp * 255).astype(np.uint8)\n",
        "plt.imshow(disp, cmap='gray')\n",
        "plt.gcf().set_size_inches(10, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "s_nI5Sk2STJi",
        "outputId": "070ad548-58ad-43d2-f7aa-7b1fa3b3ba80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### new"
      ],
      "metadata": {
        "id": "-diMDzuslKXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "max_frame_count = 0\n",
        "\n",
        "training_filepaths = []\n",
        "training_labels = []\n",
        "print(\"Checking training reconstructions\")\n",
        "for act_class in range(10):\n",
        "    class_directory = \"/content/reconstructions/DVS128/train/{0}\".format(act_class)\n",
        "    for reconstruction in os.listdir(class_directory):\n",
        "      current_recon_dir = os.path.join(class_directory, reconstruction)\n",
        "      training_filepaths.append(current_recon_dir)\n",
        "      training_labels.append(act_class)\n",
        "      frame_count = 0\n",
        "      for frame in os.listdir(\"{0}/reconstruction\".format(current_recon_dir)):\n",
        "        f = os.path.join(\"{0}/reconstruction\".format(current_recon_dir), frame)\n",
        "        if frame.endswith('.png'):\n",
        "          frame_count += 1\n",
        "      if(frame_count > max_frame_count):\n",
        "        max_frame_count = frame_count\n",
        "\n",
        "testing_filepaths = []\n",
        "testing_labels = []\n",
        "print(\"Checking testing reconstructions\")\n",
        "for act_class in range(10):\n",
        "    class_directory = \"/content/reconstructions/DVS128/test/{0}\".format(act_class)\n",
        "    for reconstruction in os.listdir(class_directory):\n",
        "      current_recon_dir = os.path.join(class_directory, reconstruction)\n",
        "      testing_filepaths.append(current_recon_dir)\n",
        "      testing_labels.append(act_class)\n",
        "      frame_count = 0\n",
        "      for frame in os.listdir(\"{0}/reconstruction\".format(current_recon_dir)):\n",
        "        f = os.path.join(\"{0}/reconstruction\".format(current_recon_dir), frame)\n",
        "        if frame.endswith('.png'):\n",
        "          frame_count += 1\n",
        "      if(frame_count > max_frame_count):\n",
        "        max_frame_count = frame_count\n",
        "\n",
        "training_filepaths, validation_filepaths, training_labels, validation_labels = train_test_split(training_filepaths, training_labels, test_size=0.2, random_state=4)\n",
        "\n",
        "print(\"The maximum video length in the dataset is {0} frames\".format(max_frame_count))\n",
        "print(\"Training samples: {0}\".format(len(training_filepaths)))\n",
        "print(\"Validation samples: {0}\".format(len(validation_filepaths)))\n",
        "print(\"Testing samples: {0}\".format(len(testing_filepaths)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i4nfLxCNegh",
        "outputId": "32d86b37-a6b2-457f-823a-de108cb3584f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking training reconstructions\n",
            "Checking testing reconstructions\n",
            "The maximum video length in the dataset is 279 frames\n",
            "Training samples: 862\n",
            "Validation samples: 216\n",
            "Testing samples: 264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import imageio\n",
        "from keras.utils import np_utils\n",
        "from itertools import islice, cycle\n",
        "\n",
        "x_train = []\n",
        "print(\"Loading training reconstructions\")\n",
        "for act_class in range(10):\n",
        "    print(' class {0}'.format(act_class))\n",
        "    class_directory = \"/content/reconstructions/DVS128/train/{0}\".format(act_class)\n",
        "    for reconstruction in os.listdir(class_directory):\n",
        "      current_recon_dir = os.path.join(class_directory, reconstruction)\n",
        "      current_recon = []\n",
        "      for frame in os.listdir(\"{0}/reconstruction\".format(current_recon_dir)):\n",
        "        f = os.path.join(\"{0}/reconstruction\".format(current_recon_dir), frame)\n",
        "        if frame.endswith('.png'):\n",
        "          im = imageio.imread(f)\n",
        "          current_recon.append(im)\n",
        "      current_recon = list(islice(cycle(current_recon), max_frame_count))\n",
        "      x_train.append(current_recon)\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], x_train.shape[3], 1)\n",
        "train_mean = np.mean(x_train)\n",
        "train_max = np.max(x_train)\n",
        "del x_train\n",
        "\n",
        "print(\"The mean of the training dataset is: {0}\".format(train_mean))\n",
        "print(\"The max of the training dataset is: {0}\".format(train_max))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z8JM3bNtvON",
        "outputId": "fdbc53a6-f763-4119-8eb6-85fd7e58364a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training reconstructions\n",
            " class 0\n",
            " class 1\n",
            " class 2\n",
            " class 3\n",
            " class 4\n",
            " class 5\n",
            " class 6\n",
            " class 7\n",
            " class 8\n",
            " class 9\n",
            "The mean of the training dataset is: 146.90482245084465\n",
            "The max of the training dataset is: 255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.utils import np_utils\n",
        "from itertools import islice, cycle\n",
        "import imageio\n",
        "\n",
        "class MyGenerator(Sequence):\n",
        "\n",
        "    def __init__(self, video_filepaths, labels, batch_size, max_frame_count, train_mean, train_max):\n",
        "        self.video_filepaths, self.labels = video_filepaths, [np_utils.to_categorical(label, 11) for label in labels]\n",
        "        self.batch_size = batch_size\n",
        "        self.max_frame_count = max_frame_count\n",
        "        self.train_mean = train_mean\n",
        "        self.train_max = train_max\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.video_filepaths) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.video_filepaths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        x_ret = []\n",
        "        for reconstruction_dir in batch_x:\n",
        "          current_recon = []\n",
        "          for frame in os.listdir(\"{0}/reconstruction\".format(reconstruction_dir)):\n",
        "            f = os.path.join(\"{0}/reconstruction\".format(reconstruction_dir), frame)\n",
        "            if frame.endswith('.png'):\n",
        "              im = imageio.imread(f)\n",
        "              current_recon.append(im)\n",
        "          current_recon = list(islice(cycle(current_recon), self.max_frame_count))\n",
        "          x_ret.append(current_recon)\n",
        "\n",
        "        x_ret = np.array(x_ret)\n",
        "        x_ret = x_ret.reshape(x_ret.shape[0], x_ret.shape[1], x_ret.shape[2], x_ret.shape[3], 1)\n",
        "        x_ret = x_ret.astype('float16')\n",
        "        x_ret -= self.train_mean\n",
        "        x_ret /= self.train_max\n",
        "        return x_ret, np.array(batch_y)\n",
        "\n",
        "batch_size = 1\n",
        "my_training_batch_generator = MyGenerator(training_filepaths, training_labels, batch_size, max_frame_count, train_mean, train_max)\n",
        "my_validation_batch_generator = MyGenerator(validation_filepaths, validation_labels, batch_size, max_frame_count, train_mean, train_max)\n",
        "my_testing_batch_generator = MyGenerator(testing_filepaths, testing_labels, batch_size, max_frame_count, train_mean, train_max)"
      ],
      "metadata": {
        "id": "kkcMd3_9LKNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Networks"
      ],
      "metadata": {
        "id": "vp9CF6eNLPM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Conv3D Network"
      ],
      "metadata": {
        "id": "LDiKlUYlPOrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cite as:\n",
        "Channayanamath M. et al. (2021) Dynamic Hand Gesture Recognition Using 3D-Convolutional Neural Network. In: Satapathy S.C., Bhateja V., Ramakrishna Murty M., Gia Nhu N., Jayasri Kotti (eds) Communication Software and Networks. Lecture Notes in Networks and Systems, vol 134. Springer, Singapore. http://doi-org-443.webvpn.fjmu.edu.cn/10.1007/978-981-15-5397-4_16"
      ],
      "metadata": {
        "id": "fX-824CmG_3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import pickle\n",
        "\n",
        "# Initialing the Training Parameters\n",
        "batch_size = 4\n",
        "nb_classes = 11\n",
        "nb_epoch = 120\n",
        "\n",
        "# Number of convolutional filters to use at each layer\n",
        "nb_filters = 16\n",
        "# Level of pooling to perform at each layer (POOL x POOL)\n",
        "nb_pool = 3\n",
        "# Level of convolution to perform at each layer (CONV x CONV)\n",
        "nb_conv = 5\n",
        "\n",
        "# Defining the 3D Convolution Neural Network model\n",
        "model = Sequential()\n",
        "model.add(Convolution3D(nb_filters,kernel_size=nb_conv,input_shape=(max_frame_count, 128, 128, 1), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution3D(nb_filters,kernel_size=nb_conv,input_shape=(max_frame_count, 128, 128, 1), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D(pool_size=nb_pool,padding='same'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution3D(nb_filters*2,kernel_size=nb_conv,activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D(pool_size=nb_pool,padding='same'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution3D(nb_filters*4,kernel_size=nb_conv,activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution3D(nb_filters*4,kernel_size=nb_conv,activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D(pool_size=nb_pool,padding='same'))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,kernel_initializer = 'he_normal',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(nb_classes,kernel_initializer = 'he_normal'))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt=Adam(lr=0.0001)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "logdir = \"logs/scalars/conv3d_dvs128\"\n",
        "\n",
        "# Training  the model along with creating callbacks to tensorboard for graphical visualization of training process\n",
        "tbcallback = keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=True, write_images=True)\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n",
        "# hist = model.fit(x_train, y_train, validation_data=(x_val,y_val),\n",
        "#           epochs = nb_epoch,shuffle=True,verbose=1,callbacks=[tbcallback, early_stopping])\n",
        "hist = model.fit(x=my_training_batch_generator, validation_data=my_validation_batch_generator,\n",
        "          epochs=nb_epoch, shuffle=True, verbose=1, callbacks=[tbcallback, early_stopping],\n",
        "          use_multiprocessing=False, workers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLwSNFnGgwHd",
        "outputId": "22460846-7a05-4fe1-8eb7-9226c8b91534"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "144/144 [==============================] - 467s 3s/step - loss: 2.1314 - accuracy: 0.3028 - val_loss: 2.7492 - val_accuracy: 0.1019\n",
            "Epoch 2/120\n",
            "144/144 [==============================] - 464s 3s/step - loss: 1.4629 - accuracy: 0.4919 - val_loss: 4.0500 - val_accuracy: 0.1019\n",
            "Epoch 3/120\n",
            "144/144 [==============================] - 465s 3s/step - loss: 1.2573 - accuracy: 0.5371 - val_loss: 4.7104 - val_accuracy: 0.1019\n",
            "Epoch 4/120\n",
            "144/144 [==============================] - 465s 3s/step - loss: 1.1890 - accuracy: 0.5893 - val_loss: 3.3627 - val_accuracy: 0.1157\n",
            "Epoch 5/120\n",
            "144/144 [==============================] - 465s 3s/step - loss: 1.0793 - accuracy: 0.6288 - val_loss: 1.2414 - val_accuracy: 0.5463\n",
            "Epoch 6/120\n",
            "144/144 [==============================] - 464s 3s/step - loss: 0.9705 - accuracy: 0.6357 - val_loss: 0.8889 - val_accuracy: 0.6898\n",
            "Epoch 7/120\n",
            "144/144 [==============================] - 464s 3s/step - loss: 1.0216 - accuracy: 0.6288 - val_loss: 1.1616 - val_accuracy: 0.6574\n",
            "Epoch 8/120\n",
            "144/144 [==============================] - 464s 3s/step - loss: 0.9149 - accuracy: 0.6937 - val_loss: 1.1551 - val_accuracy: 0.6296\n",
            "Epoch 9/120\n",
            "144/144 [==============================] - 464s 3s/step - loss: 0.7848 - accuracy: 0.7158 - val_loss: 1.3676 - val_accuracy: 0.6065\n",
            "Epoch 10/120\n",
            "144/144 [==============================] - 465s 3s/step - loss: 0.7504 - accuracy: 0.7401 - val_loss: 0.9583 - val_accuracy: 0.6481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/MyDrive/models/conv3d_dvs128_recon.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "# del model  # deletes the existing model"
      ],
      "metadata": {
        "id": "dFYWD62YqDG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results"
      ],
      "metadata": {
        "id": "E11i0ym7i-hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/models/conv3d_dvs128.h5')"
      ],
      "metadata": {
        "id": "q9MRmrGYNsiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x=my_testing_batch_generator, verbose=0)\n",
        "y_pred = model.predict(x=my_testing_batch_generator)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73FRr5d-cEmw",
        "outputId": "6d7400c1-60a9-41c8-d3b1-9d03f57b6a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.0933377742767334\n",
            "Test accuracy: 0.6325757503509521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(testing_labels, y_pred.argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSETzBH1meBY",
        "outputId": "7f654e8d-8b7a-40c3-a592-a34e19189e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.88      0.66        24\n",
            "           1       0.85      0.96      0.90        24\n",
            "           2       0.88      0.88      0.88        24\n",
            "           3       0.43      0.92      0.59        24\n",
            "           4       0.42      0.21      0.28        24\n",
            "           5       0.61      0.58      0.60        24\n",
            "           6       0.52      0.71      0.60        24\n",
            "           7       0.76      0.60      0.67        48\n",
            "           8       1.00      0.21      0.34        24\n",
            "           9       0.91      0.42      0.57        24\n",
            "\n",
            "    accuracy                           0.63       264\n",
            "   macro avg       0.69      0.64      0.61       264\n",
            "weighted avg       0.70      0.63      0.61       264\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import seaborn as sns\n",
        "\n",
        "#Create confusion matrix and normalizes it over predicted (columns)\n",
        "result = confusion_matrix(testing_labels, y_pred.argmax(axis=1), normalize='pred')\n",
        "\n",
        "ax = sns.heatmap(result, annot=False, cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix for Reconstructed DVS128 Gesture Classification with Conv3D Network\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([i for i in range(12)])\n",
        "ax.yaxis.set_ticklabels([i for i in range(12)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "WJFTxqDYjImq",
        "outputId": "91bd79aa-113a-4c35-ac5d-6aa6b1799db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0.5, '0'),\n",
              " Text(0, 1.5, '1'),\n",
              " Text(0, 2.5, '2'),\n",
              " Text(0, 3.5, '3'),\n",
              " Text(0, 4.5, '4'),\n",
              " Text(0, 5.5, '5'),\n",
              " Text(0, 6.5, '6'),\n",
              " Text(0, 7.5, '7'),\n",
              " Text(0, 8.5, '8'),\n",
              " Text(0, 9.5, '9')]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conv LSTM"
      ],
      "metadata": {
        "id": "rEhGdHoqPEX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import TensorBoard\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# config = tf.compat.v1.ConfigProto\n",
        "# config.gpu_options.allow_growth = True\n",
        "# tf.Session(config = config)\n",
        "\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)\n",
        "\n",
        "# config = tf.ConfigProto(device_count ={'GPU': 0})\n",
        "# sess = tf.Session(config=config)\n",
        "\n",
        "timesteps = max_frame_count\n",
        "width = 128\n",
        "height = 128\n",
        "channels = 1\n",
        "action_num = 11\n",
        "\n",
        "model = models.Sequential(\n",
        "    [\n",
        "        layers.Input(\n",
        "            shape=(timesteps, width, height, channels)\n",
        "        ),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=16, kernel_size=(3, 3), padding=\"same\", return_sequences=True, dropout=0.1, recurrent_dropout=0.1\n",
        "        ),\n",
        "        layers.MaxPool3D(\n",
        "            pool_size=(1, 2, 2), strides=(1, 2, 2), padding=\"same\"\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=8, kernel_size=(3, 3), padding=\"same\", return_sequences=True, dropout=0.1, recurrent_dropout=0.1\n",
        "        ),\n",
        "        layers.MaxPool3D(\n",
        "            pool_size=(1, 2, 2), strides=(1, 2, 2), padding=\"same\"\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ConvLSTM2D(\n",
        "            filters=4, kernel_size=(3, 3), padding=\"same\", return_sequences=False, dropout=0.1, recurrent_dropout=0.1\n",
        "        ),\n",
        "        layers.MaxPool2D(\n",
        "            pool_size=(2, 2), strides=(2, 2), padding=\"same\"\n",
        "        ),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(action_num, activation='softmax')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n",
        "logdir = \"logs/NMNIST_ConvLSTM\"\n",
        "# Training  the model along with creating callbacks to tensorboard for graphical visualization of training process\n",
        "tbcallback = keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "hist = model.fit(x=my_training_batch_generator, validation_data=my_validation_batch_generator,\n",
        "          epochs=120, shuffle=True, verbose=1, callbacks=[tbcallback, early_stopping],\n",
        "          use_multiprocessing=False, workers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "7a1d7481-ea60-493c-fbd5-8c561ef79e78",
        "id": "UrwSV4s8PEX6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            " 14/862 [..............................] - ETA: 1:07:34 - loss: 2.4717 - accuracy: 0.2143"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-dda7ff7f672e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m hist = model.fit(x=my_training_batch_generator, validation_data=my_validation_batch_generator,\n\u001b[1;32m     70\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtbcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m           use_multiprocessing=False, workers=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/MyDrive/models/conv_lstm_nmnist_recon.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "# del model  # deletes the existing model"
      ],
      "metadata": {
        "id": "ixMQX8cPPEX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results"
      ],
      "metadata": {
        "id": "Vu1XM0ekPEX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/models/conv_lstm_nmnist_recon.h5')"
      ],
      "metadata": {
        "id": "nM0RqNLdPEX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x=my_testing_batch_generator, verbose=0)\n",
        "y_pred = model.predict(x=my_testing_batch_generator)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198cdbb2-22f5-4735-cd12-ca7d444da42a",
        "id": "PdlqvuKrPEX7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.6660446524620056\n",
            "Test accuracy: 0.7960000038146973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(testing_labels, y_pred.argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcec93f7-790a-4a57-b663-5bfc3f39b38f",
        "id": "OskU8cnUPEX7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.92      0.87        75\n",
            "           1       0.96      0.96      0.96        75\n",
            "           2       0.82      0.91      0.86        75\n",
            "           3       0.77      0.57      0.66        75\n",
            "           4       0.74      0.72      0.73        75\n",
            "           5       0.67      0.71      0.69        75\n",
            "           6       0.88      0.85      0.86        75\n",
            "           7       0.85      0.84      0.85        75\n",
            "           8       0.74      0.64      0.69        75\n",
            "           9       0.71      0.84      0.77        75\n",
            "\n",
            "    accuracy                           0.80       750\n",
            "   macro avg       0.80      0.80      0.79       750\n",
            "weighted avg       0.80      0.80      0.79       750\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import seaborn as sns\n",
        "\n",
        "#Create confusion matrix and normalizes it over predicted (columns)\n",
        "result = confusion_matrix(testing_labels, y_pred.argmax(axis=1), normalize='pred')\n",
        "\n",
        "ax = sns.heatmap(result, annot=False, cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix for Reconstructed NMNIST Classification with ConvLSTM Network\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([i for i in range(10)])\n",
        "ax.yaxis.set_ticklabels([i for i in range(10)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "outputId": "b841aa4b-20b5-4737-a5b7-d60318388d17",
        "id": "ZWYb3pfnPEX8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0.5, '0'),\n",
              " Text(0, 1.5, '1'),\n",
              " Text(0, 2.5, '2'),\n",
              " Text(0, 3.5, '3'),\n",
              " Text(0, 4.5, '4'),\n",
              " Text(0, 5.5, '5'),\n",
              " Text(0, 6.5, '6'),\n",
              " Text(0, 7.5, '7'),\n",
              " Text(0, 8.5, '8'),\n",
              " Text(0, 9.5, '9')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom LTSM Network 1"
      ],
      "metadata": {
        "id": "_E2SZ06rmqWe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrtpvHGmmqWg"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "\n",
        "def build_convnet(shape=(128, 128, 1)):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(256, (3,3), padding='same', input_shape=shape))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  model.add(Conv2D(128, (5,5), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  model.add(Conv2D(64, (7,7), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  # model.add(Conv2D(64, (9,9), padding='same'))\n",
        "  # model.add(Activation('relu'))\n",
        "\n",
        "  # model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # model.add(Dense(512))\n",
        "  # model.add(Activation('relu'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msxsHtJkmqWj"
      },
      "outputs": [],
      "source": [
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.layers import TimeDistributed, GRU\n",
        "\n",
        "def action_model(shape=(20, 128, 128, 1), nbout=12):\n",
        "    # Create our convnet with (34, 34, 1) input shape\n",
        "    print(\"done\")\n",
        "    convnet = build_convnet(shape[1:])\n",
        "\n",
        "    # then create our final model\n",
        "    model = Sequential()\n",
        "    # add the convnet with (8, 34, 34, 1) shape\n",
        "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "    # here, you can also use GRU or LSTM\n",
        "    model.add(GRU(64))\n",
        "    # and finally, we make a decision network\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(nbout, activation='softmax'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf22722-4f2b-4ae7-f8e9-500f070bf625",
        "id": "xjVCDB4rmqWk"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "862/862 [==============================] - 625s 713ms/step - loss: 2.3508 - accuracy: 0.1462 - val_loss: 2.2179 - val_accuracy: 0.2130\n",
            "Epoch 2/120\n",
            "862/862 [==============================] - 613s 710ms/step - loss: 2.0098 - accuracy: 0.2181 - val_loss: 1.3840 - val_accuracy: 0.4491\n",
            "Epoch 3/120\n",
            "862/862 [==============================] - 611s 709ms/step - loss: 1.4636 - accuracy: 0.4095 - val_loss: 1.0762 - val_accuracy: 0.5417\n",
            "Epoch 4/120\n",
            "862/862 [==============================] - 611s 709ms/step - loss: 1.1951 - accuracy: 0.5000 - val_loss: 0.8529 - val_accuracy: 0.5787\n",
            "Epoch 5/120\n",
            "862/862 [==============================] - 611s 709ms/step - loss: 0.9392 - accuracy: 0.5835 - val_loss: 0.6863 - val_accuracy: 0.6944\n",
            "Epoch 6/120\n",
            "862/862 [==============================] - 611s 709ms/step - loss: 0.7790 - accuracy: 0.6566 - val_loss: 0.5558 - val_accuracy: 0.7083\n",
            "Epoch 7/120\n",
            "862/862 [==============================] - 612s 709ms/step - loss: 0.6415 - accuracy: 0.7135 - val_loss: 0.5364 - val_accuracy: 0.7361\n",
            "Epoch 8/120\n",
            "862/862 [==============================] - 611s 708ms/step - loss: 0.5200 - accuracy: 0.7726 - val_loss: 0.6152 - val_accuracy: 0.7546\n",
            "Epoch 9/120\n",
            "862/862 [==============================] - 611s 709ms/step - loss: 0.4997 - accuracy: 0.7575 - val_loss: 0.4505 - val_accuracy: 0.7407\n",
            "Epoch 10/120\n",
            "862/862 [==============================] - 612s 709ms/step - loss: 0.3578 - accuracy: 0.8283 - val_loss: 0.4162 - val_accuracy: 0.7685\n",
            "Epoch 11/120\n",
            "862/862 [==============================] - 611s 709ms/step - loss: 0.3981 - accuracy: 0.8028 - val_loss: 0.5171 - val_accuracy: 0.7685\n",
            "Epoch 12/120\n",
            "862/862 [==============================] - 611s 708ms/step - loss: 0.2904 - accuracy: 0.8619 - val_loss: 0.4891 - val_accuracy: 0.8102\n",
            "Epoch 13/120\n",
            "862/862 [==============================] - 612s 709ms/step - loss: 0.2666 - accuracy: 0.8782 - val_loss: 0.4283 - val_accuracy: 0.8194\n",
            "Epoch 14/120\n",
            "862/862 [==============================] - 610s 708ms/step - loss: 0.1818 - accuracy: 0.9281 - val_loss: 0.4663 - val_accuracy: 0.8426\n",
            "Epoch 15/120\n",
            "862/862 [==============================] - 610s 708ms/step - loss: 0.1292 - accuracy: 0.9582 - val_loss: 0.3078 - val_accuracy: 0.8704\n",
            "Epoch 16/120\n",
            "862/862 [==============================] - 611s 708ms/step - loss: 0.0830 - accuracy: 0.9733 - val_loss: 0.4859 - val_accuracy: 0.8472\n",
            "Epoch 17/120\n",
            "862/862 [==============================] - 611s 708ms/step - loss: 0.0915 - accuracy: 0.9733 - val_loss: 0.6151 - val_accuracy: 0.8426\n",
            "Epoch 18/120\n",
            "862/862 [==============================] - 610s 708ms/step - loss: 0.0538 - accuracy: 0.9803 - val_loss: 0.5100 - val_accuracy: 0.8704\n",
            "Epoch 19/120\n",
            "862/862 [==============================] - 611s 708ms/step - loss: 0.0404 - accuracy: 0.9907 - val_loss: 0.4652 - val_accuracy: 0.8472\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import TensorBoard\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = action_model((max_frame_count, 128, 128, 1), 11)\n",
        "opt = Adam(lr=0.0001, decay=1e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)\n",
        "logdir = \"logs/NMNIST_ConvLSTM\"\n",
        "# Training  the model along with creating callbacks to tensorboard for graphical visualization of training process\n",
        "tbcallback = keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "\n",
        "hist = model.fit(x=my_training_batch_generator, validation_data=my_validation_batch_generator,\n",
        "          epochs=120, shuffle=True, verbose=1, callbacks=[tbcallback, early_stopping],\n",
        "          use_multiprocessing=False, workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/MyDrive/models/custom_conv_lstm_dvs128_recon.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "# del model  # deletes the existing model"
      ],
      "metadata": {
        "id": "fjQoZ17Vnxio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Results"
      ],
      "metadata": {
        "id": "0wFOetdumqWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/models/custom_conv_lstm_dvs128_recon.h5')"
      ],
      "metadata": {
        "id": "h366gkd5nxit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x=my_testing_batch_generator, verbose=0)\n",
        "y_pred = model.predict(x=my_testing_batch_generator)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f8d8dca-66bd-4ab7-87ff-1e32252a9385",
        "id": "9VGhKcCamqWo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.8456490635871887\n",
            "Test accuracy: 0.8295454382896423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(testing_labels, y_pred.argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dAQHr8xmjN2",
        "outputId": "a7743d0a-6751-44a5-85cb-e8d044b6079d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.83      0.74        24\n",
            "           1       0.86      1.00      0.92        24\n",
            "           2       0.89      1.00      0.94        24\n",
            "           3       0.85      0.46      0.59        24\n",
            "           4       0.66      0.88      0.75        24\n",
            "           5       0.95      0.79      0.86        24\n",
            "           6       0.81      0.88      0.84        24\n",
            "           7       0.88      0.92      0.90        48\n",
            "           8       0.81      0.54      0.65        24\n",
            "           9       1.00      0.92      0.96        24\n",
            "\n",
            "    accuracy                           0.83       264\n",
            "   macro avg       0.84      0.82      0.82       264\n",
            "weighted avg       0.84      0.83      0.82       264\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import seaborn as sns\n",
        "\n",
        "#Create confusion matrix and normalizes it over predicted (columns)\n",
        "result = confusion_matrix(testing_labels, y_pred.argmax(axis=1), normalize='pred')\n",
        "\n",
        "ax = sns.heatmap(result, annot=False, cmap='Blues')\n",
        "\n",
        "ax.set_title('Confusion Matrix for DVS128 Gesture Classification with Custom ConvLSTM Network\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([i for i in range(12)])\n",
        "ax.yaxis.set_ticklabels([i for i in range(12)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "outputId": "2d75442d-e393-4e0c-f34c-d5841510da47",
        "id": "r2i3Fv6smqWp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0.5, '0'),\n",
              " Text(0, 1.5, '1'),\n",
              " Text(0, 2.5, '2'),\n",
              " Text(0, 3.5, '3'),\n",
              " Text(0, 4.5, '4'),\n",
              " Text(0, 5.5, '5'),\n",
              " Text(0, 6.5, '6'),\n",
              " Text(0, 7.5, '7'),\n",
              " Text(0, 8.5, '8'),\n",
              " Text(0, 9.5, '9')]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Presentation"
      ],
      "metadata": {
        "id": "dN4l9YvzSObc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q NMNIST_reconstructed.zip -d /content/reconstructions"
      ],
      "metadata": {
        "id": "S7qSKkoipnH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "frames = []\n",
        "dir = \"/content/reconstructions/NMNIST/Train/6/01270/reconstruction\"\n",
        "\n",
        "for frame in os.listdir(dir):\n",
        "  if frame.endswith('.png'):\n",
        "    frames.append(Image.open(\"{0}/{1}\".format(dir, frame)))\n",
        "\n",
        "# Save into a GIF file that loops forever\n",
        "frames[0].save('nmnist_train_6_01270_recontructed.gif', format='GIF',\n",
        "               append_images=frames[1:],\n",
        "               save_all=True,\n",
        "               duration=300, loop=0)"
      ],
      "metadata": {
        "id": "4iiMZnbpTG4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/DVS128_reconstructed.zip -d /content/reconstructions"
      ],
      "metadata": {
        "id": "28xZve7JSRl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "frames = []\n",
        "dir = \"/content/reconstructions/DVS128/train/6/user15_lab_0/reconstruction\"\n",
        "for frame in os.listdir(dir):\n",
        "  if frame.endswith('.png'):\n",
        "    frames.append(Image.open(\"{0}/{1}\".format(dir, frame)))\n",
        "\n",
        "# Save into a GIF file that loops forever\n",
        "frames[0].save('dvs128_train_600_reconstructed.gif', format='GIF',\n",
        "               append_images=frames[1:],\n",
        "               save_all=True,\n",
        "               duration=300, loop=0)"
      ],
      "metadata": {
        "id": "oQVWmekmU96m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XrecSO20lJWu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}